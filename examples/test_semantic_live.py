# -*- coding: utf-8 -*-
"""
SemanticProcessor å¯¦éš›æ¸¬è©¦

ç›´æ¥æ¸¬è©¦ SemanticProcessor çš„åŠŸèƒ½ï¼ˆä¸éœ€è¦å®‰è£ packageï¼‰
"""

import sys
from pathlib import Path

# åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from paddleocr_toolkit.processors.semantic_processor import SemanticProcessor


def test_basic_correction():
    """æ¸¬è©¦åŸºæœ¬éŒ¯èª¤ä¿®æ­£"""
    print("=" * 70)
    print("æ¸¬è©¦ 1ï¼šOCR éŒ¯èª¤ä¿®æ­£")
    print("=" * 70)
    
    processor = SemanticProcessor(llm_provider="ollama", model="qwen2.5:7b")
    
    if not processor.is_enabled():
        print("âŒ Ollama æœå‹™æœªå•Ÿå‹•")
        print("   è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œï¼šollama serve")
        print("   ä¸¦ä¸”å·²ä¸‹è¼‰æ¨¡å‹ï¼šollama pull qwen2.5:7b")
        return False
    
    print("âœ… Ollama æœå‹™å·²é€£æ¥")
    
    # æ¸¬è©¦æ–‡å­—ï¼ˆåŒ…å«å…¸å‹ OCR éŒ¯èª¤ï¼‰
    test_cases = [
        {
            "input": "é€™å€‹æ–‡å»ºåŒ…å«éŠ·å¤šOCRéŠ·åˆ¥å­—",
            "expected_keywords": ["æ–‡ä»¶", "éŒ¯", "å¾ˆå¤š"]
        },
        {
            "input": "PaddleOCRå·¥è¦‹åŒ…æ˜¯â€•å€‹å¼·å¤ªçš„å·¥å…¶",
            "expected_keywords": ["å·¥å…·åŒ…", "ä¸€å€‹", "å¼·å¤§", "å·¥å…·"]
        },
        {
            "input": "è«‹ä½æ„æª¢æŸ»éŒ¯æ²’",
            "expected_keywords": ["æ³¨æ„", "æª¢æŸ¥", "éŒ¯èª¤"]
        }
    ]
    
    success_count = 0
    
    for i, test in enumerate(test_cases, 1):
        print(f"\næ¸¬è©¦æ¡ˆä¾‹ {i}:")
        print(f"  åŸæ–‡: {test['input']}")
        
        corrected = processor.correct_ocr_errors(test['input'])
        print(f"  ä¿®æ­£: {corrected}")
        
        # ç°¡å–®é©—è­‰ï¼ˆæª¢æŸ¥é—œéµè©æ˜¯å¦å‡ºç¾ï¼‰
        has_improvement = any(kw in corrected for kw in test['expected_keywords'])
        
        if has_improvement:
            print("  âœ… ä¿®æ­£æˆåŠŸ")
            success_count += 1
        else:
            print("  âš ï¸  ä¿®æ­£æ•ˆæœå¾…ç¢ºèª")
    
    print(f"\nç¸½çµ: {success_count}/{len(test_cases)} å€‹æ¡ˆä¾‹é€šéé©—è­‰")
    return success_count == len(test_cases)


def test_structured_extraction():
    """æ¸¬è©¦çµæ§‹åŒ–è³‡æ–™æå–"""
    print("\n" + "=" * 70)
    print("æ¸¬è©¦ 2ï¼šçµæ§‹åŒ–è³‡æ–™æå–")
    print("=" * 70)
    
    processor = SemanticProcessor(llm_provider="ollama")
    
    if not processor.is_enabled():
        print("âŒ Ollama æœå‹™æœªå•Ÿå‹•")
        return False
    
    # æ¨¡æ“¬åç‰‡ OCR çµæœ
    business_card = """
    å¼µå°æ˜
    é«˜ç´šè»Ÿé«”å·¥ç¨‹å¸«
    ABCç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸
    é›»è©±ï¼š(02) 2345-6789
    æ‰‹æ©Ÿï¼š0912-345-678
    Email: xiaoming@abc-tech.com
    å°åŒ—å¸‚å¤§å®‰å€æ•¦åŒ–å—è·¯äºŒæ®µ123è™Ÿ5æ¨“
    """
    
    schema = {
        "name": "å§“å",
        "title": "è·ç¨±", 
        "company": "å…¬å¸",
        "phone": "é›»è©±",
        "mobile": "æ‰‹æ©Ÿ",
        "email": "é›»å­éƒµä»¶",
        "address": "åœ°å€"
    }
    
    print(f"\nè¼¸å…¥æ–‡å­—:\n{business_card}")
    print(f"\nSchema: {list(schema.keys())}")
    
    result = processor.extract_structured_data(business_card, schema)
    
    if result:
        print("\nâœ… æå–æˆåŠŸ:")
        for key, value in result.items():
            print(f"  {key}: {value}")
        return True
    else:
        print("\nâŒ æå–å¤±æ•—")
        return False


def test_summary():
    """æ¸¬è©¦æ–‡ä»¶æ‘˜è¦"""
    print("\n" + "=" * 70)
    print("æ¸¬è©¦ 3ï¼šæ–‡ä»¶æ‘˜è¦ç”Ÿæˆ")
    print("=" * 70)
    
    processor = SemanticProcessor(llm_provider="ollama")
    
    if not processor.is_enabled():
        print("âŒ Ollama æœå‹™æœªå•Ÿå‹•")
        return False
    
    long_text = """
    PaddleOCR Toolkit 2.0 æ˜¯ä¸€å€‹å…¨é¢å‡ç´šçš„ OCR å·¥å…·åŒ…ï¼Œæ¡ç”¨æ¨¡çµ„åŒ–æ¶æ§‹è¨­è¨ˆã€‚
    ä¸»è¦ç‰¹é»åŒ…æ‹¬ï¼š5 å€‹å°ˆæ¥­ Processorï¼ˆHybridPDFProcessorã€BasicProcessorã€
    StructureProcessorã€FormulaProcessorã€TranslationProcessorï¼‰ï¼Œ
    è¼•é‡ç´š Facade APIï¼Œ100% å‘å¾Œç›¸å®¹ï¼Œæ¸¬è©¦è¦†è“‹ç‡é” 89%ã€‚
    
    v3.0 ç‰ˆæœ¬è¨ˆç•«å¼•å…¥ AI å¢å¼·åŠŸèƒ½ï¼ŒåŒ…æ‹¬ SemanticProcessor èªç¾©è™•ç†å™¨ã€
    å¤šèªè¨€è‡ªå‹•åµæ¸¬ã€äº’å‹•å¼æ ¡å° UI ç­‰å‰µæ–°åŠŸèƒ½ã€‚SemanticProcessor åˆ©ç”¨
    å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªå‹•ä¿®æ­£ OCR éŒ¯èª¤ï¼Œé æœŸå¯æå‡è­˜åˆ¥æº–ç¢ºç‡ 15% ä»¥ä¸Šã€‚
    
    è©²å°ˆæ¡ˆå·²åœ¨ GitHub é–‹æºï¼Œæä¾›å®Œæ•´çš„æŠ€è¡“æ–‡ä»¶ã€API æŒ‡å—ã€é·ç§»æŒ‡å—
    å’Œæ¸¬è©¦æŒ‡å—ï¼Œæ–¹ä¾¿é–‹ç™¼è€…å¿«é€Ÿä¸Šæ‰‹ä½¿ç”¨ã€‚
    """
    
    print(f"\nåŸæ–‡é•·åº¦: {len(long_text)} å­—")
    print(f"åŸæ–‡:\n{long_text}")
    
    summary = processor.summarize_document(long_text, max_length=80)
    
    print(f"\næ‘˜è¦é•·åº¦: {len(summary)} å­—")
    print(f"æ‘˜è¦:\n{summary}")
    
    if summary and len(summary) <= 100:
        print("\nâœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ")
        return True
    else:
        print("\nâŒ æ‘˜è¦ç”Ÿæˆå¤±æ•—")
        return False


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("\nğŸ”¬ SemanticProcessor åŠŸèƒ½æ¸¬è©¦\n")
    
    results = {
        "OCRéŒ¯èª¤ä¿®æ­£": test_basic_correction(),
        "çµæ§‹åŒ–æå–": test_structured_extraction(),
        "æ–‡ä»¶æ‘˜è¦": test_summary(),
    }
    
    # ç¸½çµ
    print("\n" + "=" * 70)
    print("æ¸¬è©¦ç¸½çµ")
    print("=" * 70)
    
    for test_name, passed in results.items():
        status = "âœ… é€šé" if passed else "âŒ å¤±æ•—"
        print(f"  {test_name}: {status}")
    
    total = len(results)
    passed = sum(results.values())
    
    print(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼SemanticProcessor å·¥ä½œæ­£å¸¸ï¼")
    elif passed > 0:
        print("\nâš ï¸  éƒ¨åˆ†æ¸¬è©¦é€šéï¼Œè«‹æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦é …ç›®")
    else:
        print("\nâŒ æ‰€æœ‰æ¸¬è©¦å¤±æ•—ï¼Œè«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œ")


if __name__ == "__main__":
    main()
