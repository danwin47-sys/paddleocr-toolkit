#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“„ æ–‡æ¡£åˆ†ç±»å™¨ - PaddleOCR Toolkit ç¤ºä¾‹é¡¹ç›®
è‡ªåŠ¨åˆ†ç±»æ‰«ææ–‡æ¡£ç±»å‹

ä½¿ç”¨æ–¹æ³•:
    python document_classifier.py documents/
"""

import sys
from pathlib import Path
from typing import Dict, List
import json
import re

sys.path.insert(0, str(Path(__file__).parent.parent))

from paddle_ocr_tool import PaddleOCRTool


class DocumentClassifier:
    """æ–‡æ¡£åˆ†ç±»å™¨"""
    
    # æ–‡æ¡£ç±»å‹ç‰¹å¾å…³é”®è¯
    DOCUMENT_PATTERNS = {
        "invoice": ["å‘ç¥¨", "Invoice", "ç¨å·", "Tax", "é‡‘é¢", "Amount"],
        "contract": ["åˆåŒ", "Contract", "ç”²æ–¹", "ä¹™æ–¹", "Party A", "Party B"],
        "resume": ["ç®€å†", "Resume", "æ•™è‚²", "Education", "å·¥ä½œç»éªŒ", "Experience"],
        "report": ["æŠ¥å‘Š", "Report", "æ‘˜è¦", "Abstract", "ç»“è®º", "Conclusion"],
        "certificate": ["è¯ä¹¦", "Certificate", "è®¤è¯", "é¢å‘", "Issued"],
        "id_card": ["èº«ä»½è¯", "ID Card", "å§“å", "Name", "æ€§åˆ«", "Gender"],
        "business_card": ["åç‰‡", "èŒä½", "Position", "ç”µè¯", "Tel", "Email"],
        "letter": ["ä¿¡å‡½", "Letter", "æ•¬å¯", "Dear", "æ­¤è‡´", "Sincerely"],
    }
    
    def __init__(self):
        """åˆå§‹åŒ–OCRå¼•æ“"""
        print("åˆå§‹åŒ–æ–‡æ¡£åˆ†ç±»å™¨...")
        self.ocr_tool = PaddleOCRTool(mode="basic")
        print("å°±ç»ª!\n")
    
    def classify_document(self, image_path: str) -> Dict:
        """
        åˆ†ç±»æ–‡æ¡£
        
        Args:
            image_path: æ–‡æ¡£å›¾ç‰‡è·¯å¾„
            
        Returns:
            åˆ†ç±»ç»“æœå­—å…¸
        """
        print(f"åˆ†ç±»æ–‡æ¡£: {image_path}")
        
        # OCRè¯†åˆ«
        results = self.ocr_tool.process_image(image_path)
        
        # åˆå¹¶æ–‡å­—
        all_text = " ".join([r.text for r in results])
        
        # åˆ†ç±»
        doc_type, confidence = self._classify_text(all_text)
        
        return{
            "file": str(image_path),
            "type": doc_type,
            "confidence": confidence,
            "text_length": len(all_text),
            "ocr_results_count": len(results)
        }
    
    def _classify_text(self, text: str) -> tuple:
        """åˆ†ç±»æ–‡å­—"""
        scores = {}
        
        for doc_type, keywords in self.DOCUMENT_PATTERNS.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > 0:
                scores[doc_type] = score
        
        if not scores:
            return "unknown", 0.0
        
        # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„ç±»å‹
        best_type = max(scores, key=scores.get)
        max_score = scores[best_type]
        total_keywords = len(self.DOCUMENT_PATTERNS[best_type])
        
        confidence = max_score / total_keywords
        
        return best_type, confidence
    
    def batch_classify(self, directory: Path) -> List[Dict]:
        """æ‰¹æ¬¡åˆ†ç±»"""
        results = []
        
        image_files = list(directory.glob("*.jpg")) + \
                     list(directory.glob("*.png")) + \
                     list(directory.glob("*.jpeg"))
        
        if not image_files:
            print("æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return results
        
        print(f"æ‰¾åˆ° {len(image_files)} ä¸ªæ–‡ä»¶\n")
        
        for i, img_file in enumerate(image_files, 1):
            print(f"[{i}/{len(image_files)}]")
            result = self.classify_document(str(img_file))
            results.append(result)
            
            print(f"  ç±»å‹: {result['type']}")
            print(f"  ä¿¡å¿ƒåº¦: {result['confidence']:.1%}\n")
        
        return results
    
    def organize_by_type(self, results: List[Dict], output_dir: Path):
        """æŒ‰ç±»å‹ç»„ç»‡æ–‡ä»¶"""
        output_dir.mkdir(exist_ok=True)
        
        # æŒ‰ç±»å‹åˆ†ç»„
        by_type = {}
        for result in results:
            doc_type = result['type']
            if doc_type not in by_type:
                by_type[doc_type] = []
            by_type[doc_type].append(result['file'])
        
        # åˆ›å»ºç±»å‹ç›®å½•å¹¶ç§»åŠ¨æ–‡ä»¶
        for doc_type, files in by_type.items():
            type_dir = output_dir / doc_type
            type_dir.mkdir(exist_ok=True)
            
            print(f"\n{doc_type}: {len(files)} ä¸ªæ–‡ä»¶")
            for file_path in files:
                print(f"  - {Path(file_path).name}")


def main():
    """ä¸»ç¨‹åº"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python document_classifier.py <å›¾ç‰‡æˆ–èµ„æ–™å¤¹>")
        return
    
    input_path = Path(sys.argv[1])
    classifier = DocumentClassifier()
    
    if input_path.is_file():
        # å•ä¸ªæ–‡ä»¶
        result = classifier.classify_document(str(input_path))
        print(f"\nç±»å‹: {result['type']}")
        print(f"ä¿¡å¿ƒåº¦: {result['confidence']:.1%}")
        
    elif input_path.is_dir():
        # æ‰¹æ¬¡åˆ†ç±»
        results = classifier.batch_classify(input_path)
        
        # ä¿å­˜ç»“æœ
        with open("classification_results.json", 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # ç»Ÿè®¡
        print("\n" + "="*50)
        print("åˆ†ç±»ç»Ÿè®¡")
        print("="*50)
        
        type_counts = {}
        for result in results:
            doc_type = result['type']
            type_counts[doc_type] = type_counts.get(doc_type, 0) + 1
        
        for doc_type, count in sorted(type_counts.items()):
            print(f"{doc_type}: {count}")
        
        print("="*50)
        
        # è¯¢é—®æ˜¯å¦ç»„ç»‡æ–‡ä»¶
        print("\næŒ‰ç±»å‹ç»„ç»‡æ–‡ä»¶åˆ°output/ç›®å½•ï¼Ÿ(y/n): ", end='')
        if input().lower() == 'y':
            classifier.organize_by_type(results, Path("output"))
            print("ç»„ç»‡å®Œæˆï¼")


if __name__ == "__main__":
    main()
