# SemanticProcessor ä½¿ç”¨æŒ‡å—

> v3.0 æ–°åŠŸèƒ½ï¼šAI é©…å‹•çš„ OCR å¾Œè™•ç†

---

## ğŸ“– æ¦‚è¿°

**SemanticProcessor** æ˜¯ PaddleOCR Toolkit v3.0 å¼•å…¥çš„èªç¾©è™•ç†å™¨ï¼Œåˆ©ç”¨å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªå‹•ä¿®æ­£ OCR è­˜åˆ¥ä¸­çš„å¸¸è¦‹éŒ¯èª¤ï¼Œæå‡æ–‡å­—çš„èªç¾©æº–ç¢ºæ€§å’Œå¯è®€æ€§ã€‚

### æ ¸å¿ƒåŠŸèƒ½

| åŠŸèƒ½ | èªªæ˜ | æå‡æ•ˆæœ |
|------|------|----------|
| **OCR éŒ¯èª¤ä¿®æ­£** | è‡ªå‹•ä¿®æ­£éŒ¯åˆ¥å­—ã€æ¨™é»éŒ¯èª¤ | æº–ç¢ºç‡ +15% |
| **çµæ§‹åŒ–è³‡æ–™æå–** | å¾ OCR æ–‡å­—æå– JSON è³‡æ–™ | æ•ˆç‡ +50% |
| **æª”æ¡ˆæ‘˜è¦** | è‡ªå‹•ç”Ÿæˆæª”æ¡ˆæ‘˜è¦ | ç¯€çœæ™‚é–“ 80% |

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### æ–¹æ³• 1ï¼šé€é Facadeï¼ˆæ¨è–¦ï¼‰

æœ€ç°¡å–®çš„ä½¿ç”¨æ–¹å¼ï¼š

```python
from paddle_ocr_facade import PaddleOCRFacade

# å•Ÿç”¨èªç¾©è™•ç†
facade = PaddleOCRFacade(
    mode="basic",
    enable_semantic=True,      # å•Ÿç”¨èªç¾©è™•ç†
    llm_provider="ollama",     # LLM æä¾›å•†
    llm_model="qwen2.5:7b"     # æ¨¡å‹ï¼ˆå¯é¸ï¼‰
)

# ä¿®æ­£ OCR éŒ¯èª¤
ocr_text = "é€™å€‹æ–‡å»ºåŒ…å«éŠ·å¤šéŒ¯æ²’"
corrected = facade.correct_text(ocr_text)
print(corrected)  # "é€™å€‹æª”æ¡ˆåŒ…å«å¾ˆå¤šéŒ¯èª¤"
```

### æ–¹æ³• 2ï¼šç›´æ¥ä½¿ç”¨ SemanticProcessor

æ›´ç²¾ç´°çš„æ§åˆ¶ï¼š

```python
from paddleocr_toolkit.processors import SemanticProcessor

# åˆå§‹åŒ–
processor = SemanticProcessor(
    llm_provider="ollama",
    model="qwen2.5:14b"
)

# ä½¿ç”¨
corrected = processor.correct_ocr_errors("æ–‡å»ºæœ‰éŒ¯æ²’")
```

---

## ğŸ’¡ è©³ç´°åŠŸèƒ½èªªæ˜

### 1. OCR éŒ¯èª¤ä¿®æ­£

è‡ªå‹•è­˜åˆ¥ä¸¦ä¿®æ­£å¸¸è¦‹çš„ OCR éŒ¯èª¤ï¼š

```python
# ç¯„ä¾‹ 1ï¼šéŒ¯åˆ¥å­—ä¿®æ­£
text = "é€™å€‹æª”æ¡ˆåŒ…å«å¾ˆå¤šOCRéŒ¯åˆ¥å­—"
corrected = facade.correct_text(text)
# è¼¸å‡ºï¼šã€Œé€™å€‹æª”æ¡ˆåŒ…å«å¾ˆå¤šOCRéŒ¯åˆ¥å­—ã€

# ç¯„ä¾‹ 2ï¼šç¹é«”ä¸­æ–‡ä¿æŒ
text = "è«‹æ³¨æ„æª¢æŸ¥é€™ä»½æª”æ¡ˆ"
corrected = facade.correct_text(text, language="zh")
# è¼¸å‡ºï¼šã€Œè«‹æ³¨æ„æª¢æŸ¥é€™ä»½æª”æ¡ˆã€ï¼ˆä¿æŒç¹é«”ï¼‰
```

### 2. çµæ§‹åŒ–è³‡æ–™æå–

å¾éçµæ§‹åŒ–æ–‡å­—æå–çµæ§‹åŒ–è³‡æ–™ï¼š

```python
# åç‰‡æ–‡å­—
business_card = """
å¼µå°æ˜
è³‡æ·±å·¥ç¨‹å¸«
ç§‘æŠ€å…¬å¸
é›»è©±ï¼š02-1234-5678
Email: zhang@example.com
"""

# å®šç¾© Schema
schema = {
    "name": "å§“å",
    "title": "è·ç¨±",
    "company": "å…¬å¸",
    "phone": "é›»è©±",
    "email": "Email"
}

# æå–
data = facade.extract_structured_data(business_card, schema)

# è¼¸å‡ºï¼š
# {
#     "name": "å¼µå°æ˜",
#     "title": "è³‡æ·±å·¥ç¨‹å¸«",
#     "company": "ç§‘æŠ€å…¬å¸",
#     "phone": "02-1234-5678",
#     "email": "zhang@example.com"
# }
```

### 3. æª”æ¡ˆæ‘˜è¦

ç”Ÿæˆç°¡æ½”çš„æª”æ¡ˆæ‘˜è¦ï¼š

```python
# é•·æ–‡å­—
long_text = """
PaddleOCR Toolkit æ˜¯ä¸€å€‹åŠŸèƒ½å¼·å¤§çš„ OCR å·¥å…·åŒ…...
ï¼ˆçœç•¥ 500 å­—ï¼‰
"""

# ç”Ÿæˆæ‘˜è¦
summary = processor.summarize_document(long_text, max_length=100)
print(summary)  # 80-100 å­—çš„ç²¾ç°¡æ‘˜è¦
```

---

## âš™ï¸ é…ç½®é¸é …

### LLM æä¾›å•†

æ”¯æ´å¤šç¨® LLM æä¾›å•†ï¼š

#### Ollamaï¼ˆæœ¬åœ°éƒ¨ç½²ï¼Œæ¨è–¦ï¼‰

```python
facade = PaddleOCRFacade(
    enable_semantic=True,
    llm_provider="ollama",
    llm_model="qwen2.5:7b"  # æˆ– qwen2.5:14bï¼ˆæ›´æº–ç¢ºï¼‰
)
```

**å„ªé»**ï¼š
- âœ… å…è²»
- âœ… éš±ç§ä¿è­·ï¼ˆæœ¬åœ°åŸ·è¡Œï¼‰
- âœ… ç„¡ç¶²è·¯å»¶é²

**å‰æ**ï¼š
```bash
# 1. å®‰è£ Ollama
# https://ollama.ai/download

# 2. å•Ÿå‹•æœå‹™
ollama serve

# 3. ä¸‹è¼‰æ¨¡å‹
ollama pull qwen2.5:7b
```

#### OpenAIï¼ˆé›²ç«¯æœå‹™ï¼‰

```python
facade = PaddleOCRFacade(
    enable_semantic=True,
    llm_provider="openai",
    llm_model="gpt-3.5-turbo",
    api_key="your-api-key"  # éœ€è¦ API é‡‘é‘°
)
```

**å„ªé»**ï¼š
- âœ… æ•ˆæœæ›´ä½³
- âœ… ç„¡éœ€æœ¬åœ°éƒ¨ç½²

**ç¼ºé»**ï¼š
- âŒ éœ€è¦ä»˜è²»
- âŒ éœ€è¦ç¶²è·¯é€£ç·š

---

## ğŸ¯ æœ€ä½³å¯¦è¸

### 1. é¸æ“‡åˆé©çš„æ¨¡å‹

| å ´æ™¯ | æ¨è–¦æ¨¡å‹ | ç†ç”± |
|------|---------|------|
| æ—¥å¸¸ä½¿ç”¨ | `qwen2.5:7b` | é€Ÿåº¦å¿«ï¼Œæ•ˆæœå¥½ |
| é«˜ç²¾åº¦éœ€æ±‚ | `qwen2.5:14b` | æº–ç¢ºç‡æ›´é«˜ |
| è‹±æ–‡ç‚ºä¸» | `gpt-3.5-turbo` | è‹±æ–‡æ•ˆæœæœ€ä½³ |

### 2. ç¹é«”ä¸­æ–‡è™•ç†

ç¢ºä¿ç¹é«”è¼¸å‡ºï¼š

```python
corrected = processor.correct_ocr_errors(
    text,
    language="zh"  # æ˜ç¢ºæŒ‡å®šä¸­æ–‡
)
```

### 3. æ‰¹æ¬¡è™•ç†

å°æ–¼å¤§é‡æ–‡å­—ï¼Œå»ºè­°åˆ†æ‰¹è™•ç†ï¼š

```python
def batch_correct(texts, batch_size=10):
    results = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        for text in batch:
            corrected = facade.correct_text(text)
            results.append(corrected)
    return results
```

---

## ğŸ”§ é€²éšç”¨æ³•

### è‡ªå®šç¾©æç¤ºè©

```python
# ç›´æ¥ä½¿ç”¨ SemanticProcessor
processor = SemanticProcessor(llm_provider="ollama")

# è‡ªå®šç¾©æç¤ºè©
custom_prompt = """
è«‹ä¿®æ­£ä»¥ä¸‹ OCR æ–‡å­—ï¼Œä¿æŒå°ˆæ¥­è¡“èªä¸è®Šï¼š
{text}

ä¿®æ­£å¾Œï¼š
"""

# ä½¿ç”¨
response = processor.llm_client.generate(
    custom_prompt.format(text="åŸå§‹æ–‡å­—")
)
```

### éŒ¯èª¤è™•ç†

```python
try:
    corrected = facade.correct_text(text)
except Exception as e:
    logging.error(f"èªç¾©è™•ç†å¤±æ•—: {e}")
    # é™ç´šè™•ç†ï¼šä½¿ç”¨åŸå§‹æ–‡å­—
    corrected = text
```

---

## ğŸ“Š æ•ˆèƒ½åŸºæº–

æ¸¬è©¦ç’°å¢ƒï¼šOllama + qwen2.5:7bï¼ŒCPU æ¨¡å¼

| æ“ä½œ | è™•ç†æ™‚é–“ | æº–ç¢ºç‡æå‡ |
|------|---------|-----------|
| çŸ­æ–‡å­—ä¿®æ­£ï¼ˆ<100å­—ï¼‰ | ~1-2ç§’ | +15% |
| çµæ§‹åŒ–æå– | ~2-3ç§’ | +20% |
| æª”æ¡ˆæ‘˜è¦ï¼ˆ500å­—ï¼‰ | ~3-5ç§’ | N/A |

---

## â“ å¸¸è¦‹å•é¡Œ

### Q1: Ollama æœå‹™ç„¡æ³•é€£ç·šï¼Ÿ

**A**: ç¢ºä¿ Ollama æ­£åœ¨åŸ·è¡Œï¼š
```bash
# æª¢æŸ¥æœå‹™ç‹€æ…‹
curl http://localhost:11434/api/tags

# å¦‚æœå¤±æ•—ï¼Œå•Ÿå‹•æœå‹™
ollama serve
```

### Q2: ç‚ºä»€éº¼è¼¸å‡ºæ˜¯ç°¡é«”ä¸­æ–‡ï¼Ÿ

**A**: v3.0 å·²æœ€ä½³åŒ–æç¤ºè©ï¼Œæ˜ç¢ºè¦æ±‚ç¹é«”è¼¸å‡ºã€‚å¦‚ä»æœ‰å•é¡Œï¼š
- ç¢ºèªä½¿ç”¨æœ€æ–°ç‰ˆæœ¬
- å˜—è©¦æ›´å¤§çš„æ¨¡å‹ï¼ˆqwen2.5:14bï¼‰

### Q3: èªç¾©è™•ç†å¤ªæ…¢ï¼Ÿ

**A**: æœ€ä½³åŒ–å»ºè­°ï¼š
- ä½¿ç”¨è¼ƒå°æ¨¡å‹ï¼ˆqwen2.5:7bï¼‰
- ç¸®çŸ­è¼¸å…¥æ–‡å­—é•·åº¦
- è€ƒæ…®å‡ç´šç¡¬é«”æˆ–ä½¿ç”¨ GPU

### Q4: å¯ä»¥é›¢ç·šä½¿ç”¨å—ï¼Ÿ

**A**: å¯ä»¥ï¼ä½¿ç”¨ Ollama æœ¬åœ°éƒ¨ç½²å³å¯å®Œå…¨é›¢ç·šåŸ·è¡Œã€‚

---

## ğŸ“ å®Œæ•´ç¤ºç¯„

æª¢è¦– `examples/facade_semantic_demo.py` ç²å–å®Œæ•´çš„å¯¦ç”¨ç¯„ä¾‹ã€‚

---

**ç‰ˆæœ¬**: v3.0.0  
**æœ€å¾Œæ›´æ–°**: 2025-12-18
