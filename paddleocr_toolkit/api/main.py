#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FastAPIåç«¯ - Webç•Œé¢
v1.2.0æ–°å¢ - REST APIæœåŠ¡
"""
from __future__ import annotations  # Python 3.8 å…¼å®¹æ€§

import asyncio
import os
import time
import uuid
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Optional
from urllib.parse import quote

from fastapi import (
    BackgroundTasks,
    FastAPI,
    File,
    HTTPException,
    Query,
    Request,
    UploadFile,
    WebSocket,
    WebSocketDisconnect,
)
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel



from paddleocr_toolkit.api.file_manager import router as file_router
from paddleocr_toolkit.api.websocket_manager import manager
from paddleocr_toolkit.core.ocr_engine import OCREngineManager
from paddleocr_toolkit.plugins.loader import PluginLoader

# æ‰¾åˆ° web ç›®éŒ„
WEB_DIR = Path(__file__).parent.parent.parent / "web"
STATIC_DIR = WEB_DIR  # ç›®å‰ index.html ç›´æ¥åœ¨ web æ ¹ç›®éŒ„

app = FastAPI(
    title="PaddleOCR Toolkit API",
    description="å°ˆæ¥­ç´š OCR æ–‡ä»¶è™•ç† API",
    version="3.3.0",
    docs_url="/docs",
    redoc_url="/redoc",
)


# Global Exception Handler
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    import traceback
    error_detail = traceback.format_exc()
    print(f"[CRITICAL ERROR] {exc}")
    print(error_detail)
    return JSONResponse(
        status_code=500,
        content={"status": "error", "message": f"ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤: {str(exc)}", "detail": error_detail}
    )


# Request Logging Middleware
@app.middleware("http")
async def log_requests(request, call_next):
    import time
    start_time = time.time()
    path = request.url.path
    method = request.method
    print(f"[HTTP] {method} {path} - æ”¶åˆ°è«‹æ±‚")
    
    try:
        response = await call_next(request)
        duration = time.time() - start_time
        print(f"[HTTP] {method} {path} - å®Œæˆè™•ç† ({duration:.2f}s) - Status: {response.status_code}")
        return response
    except Exception as e:
        print(f"[HTTP] {method} {path} - è™•ç†æ™‚ç™¼ç”Ÿç•°å¸¸: {e}")
        import traceback
        print(traceback.format_exc())
        raise e

# æ›è¼‰è·¯ç”±
app.include_router(file_router)

# éœæ…‹æª”æ¡ˆæœå‹™ (å¦‚æœç›®éŒ„å­˜åœ¨)
if WEB_DIR.exists():
    app.mount("/web", StaticFiles(directory=str(WEB_DIR)), name="web")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["Content-Disposition"],  # å…è¨±å‰ç«¯è®€å–è‡ªè¨‚ header
)

# ä»»å‹™å„²å­˜
tasks = {}
results = {}
batches = {}  # æ‰¹é‡è™•ç†è¿½è¹¤

# ç°¡å–®é€Ÿç‡é™åˆ¶å™¨
rate_limits = defaultdict(list)
RATE_LIMIT = 10  # æ¯åˆ†é˜è«‹æ±‚æ•¸
RATE_LIMIT_BATCH = 3  # æ‰¹é‡è™•ç†æ¯åˆ†é˜è«‹æ±‚æ•¸
RATE_WINDOW = 60  # æ™‚é–“çª—å£ï¼ˆç§’ï¼‰

# é…ç½®
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)
OUTPUT_DIR = Path("outputs")
OUTPUT_DIR.mkdir(exist_ok=True)
PLUGIN_DIR = Path("paddleocr_toolkit/plugins")

# åˆå§‹åŒ–æ’ä»¶è¼‰å…¥å™¨
plugin_loader = PluginLoader(str(PLUGIN_DIR))
plugin_loader.load_all_plugins()

# åœ–ç‰‡å¤§å°é™åˆ¶ (é¿å… OCR è¨˜æ†¶é«”ä¸è¶³)
MAX_IMAGE_SIDE = 2500  # åƒç´ 

# å…¨åŸŸ OCR å¼•æ“å¿«å–
ocr_engine_cache = None


def check_rate_limit(client_ip: str, limit: int = RATE_LIMIT) -> bool:
    """
    æª¢æŸ¥é€Ÿç‡é™åˆ¶
    
    Args:
        client_ip: å®¢æˆ¶ç«¯ IP
        limit: è«‹æ±‚é™åˆ¶ï¼ˆé è¨­ 10/åˆ†é˜ï¼‰
    
    Returns:
        True å¦‚æœæœªè¶…é™ï¼ŒFalse å¦‚æœè¶…é™
    """
    now = time.time()
    
    # æ¸…ç†èˆŠè¨˜éŒ„
    rate_limits[client_ip] = [
        t for t in rate_limits[client_ip] 
        if now - t < RATE_WINDOW
    ]
    
    # æª¢æŸ¥æ˜¯å¦è¶…é™
    if len(rate_limits[client_ip]) >= limit:
        return False
    
    # è¨˜éŒ„è«‹æ±‚
    rate_limits[client_ip].append(now)
    return True


async def cleanup_old_tasks():
    """
    å®šæœŸæ¸…ç†èˆŠä»»å‹™ï¼Œé˜²æ­¢è¨˜æ†¶é«”æ´©æ¼å’Œç£ç¢Ÿç©ºé–“è€—ç›¡
    æ¯å°æ™‚æ¸…ç† 24 å°æ™‚å‰çš„ä»»å‹™å’Œæª”æ¡ˆ
    """
    while True:
        try:
            await asyncio.sleep(3600)  # æ¯å°æ™‚åŸ·è¡Œä¸€æ¬¡
            
            cutoff = datetime.now() - timedelta(hours=24)
            removed_tasks = 0
            removed_results = 0
            removed_files = 0
            
            # æ¸…ç†èˆŠä»»å‹™
            for task_id in list(tasks.keys()):
                task = tasks.get(task_id, {})
                task_time = task.get('created_at')
                
                if task_time and isinstance(task_time, datetime) and task_time < cutoff:
                    del tasks[task_id]
                    removed_tasks += 1
            
            # æ¸…ç†èˆŠçµæœ
            for task_id in list(results.keys()):
                if task_id not in tasks:
                    del results[task_id]
                    removed_results += 1
            
            # æ¸…ç†èˆŠæª”æ¡ˆï¼ˆä¸Šå‚³å’Œè¼¸å‡ºï¼‰
            cutoff_timestamp = cutoff.timestamp()
            
            # æ¸…ç†ä¸Šå‚³ç›®éŒ„
            for file_path in UPLOAD_DIR.glob("*"):
                if file_path.is_file():
                    try:
                        if file_path.stat().st_mtime < cutoff_timestamp:
                            file_path.unlink()
                            removed_files += 1
                    except Exception as e:
                        print(f"âš ï¸ ç„¡æ³•åˆªé™¤æª”æ¡ˆ {file_path}: {e}")
           
            # æ¸…ç†è¼¸å‡ºç›®éŒ„
            for file_path in OUTPUT_DIR.glob("*"):
                if file_path.is_file():
                    try:
                        if file_path.stat().st_mtime < cutoff_timestamp:
                            file_path.unlink()
                            removed_files += 1
                    except Exception as e:
                        print(f"âš ï¸ ç„¡æ³•åˆªé™¤æª”æ¡ˆ {file_path}: {e}")
            
            if removed_tasks > 0 or removed_results > 0 or removed_files > 0:
                print(f"ğŸ§¹ æ¸…ç†å®Œæˆ: ç§»é™¤ {removed_tasks} å€‹èˆŠä»»å‹™, {removed_results} å€‹èˆŠçµæœ, {removed_files} å€‹èˆŠæª”æ¡ˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ä»»å‹™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


@app.on_event("startup")
async def startup_event():
    """
    æ‡‰ç”¨å•Ÿå‹•æ™‚é è¼‰ OCR å¼•æ“ä¸¦å•Ÿå‹•æ¸…ç†ä»»å‹™
    """
    global ocr_engine_cache
    print("=" * 60)
    print("ğŸš€ æ­£åœ¨é è¼‰ OCR å¼•æ“...")
    print("=" * 60)
    try:
        # é è¼‰åŸºç¤æ¨¡å¼å¼•æ“ï¼ˆæœ€å¸¸ç”¨ï¼‰
        ocr_engine_cache = OCREngineManager(mode="basic", device="cpu", plugin_loader=plugin_loader)
        ocr_engine_cache.init_engine()
        print("âœ… OCR å¼•æ“é è¼‰å®Œæˆ (Basic æ¨¡å¼)")
        print("   é¦–æ¬¡ OCR è«‹æ±‚å°‡ç›´æ¥ä½¿ç”¨é è¼‰å¼•æ“ï¼Œç„¡éœ€ç­‰å¾…æ¨¡å‹è¼‰å…¥")
    except Exception as e:
        print(f"âš ï¸ OCR å¼•æ“é è¼‰å¤±æ•—: {e}")
        ocr_engine_cache = None
    
    # å•Ÿå‹•å®šæœŸæ¸…ç†ä»»å‹™
    asyncio.create_task(cleanup_old_tasks())
    print("ğŸ§¹ å·²å•Ÿå‹•å®šæœŸä»»å‹™æ¸…ç†ï¼ˆæ¯å°æ™‚åŸ·è¡Œï¼‰")
    print("=" * 60)


def resize_image_if_needed(file_path: str, max_side: int = MAX_IMAGE_SIDE) -> str:
    """
    æª¢æ¸¬ä¸¦ç¸®å°å¤§åœ–ç‰‡ä»¥é¿å… OCR è¨˜æ†¶é«”å•é¡Œ

    Args:
        file_path: åœ–ç‰‡è·¯å¾‘
        max_side: æœ€å¤§é‚Šé•·ï¼ˆé è¨­ 2500pxï¼‰

    Returns:
        è™•ç†å¾Œçš„åœ–ç‰‡è·¯å¾‘ï¼ˆç¸®å°å¾Œçš„æ–°æª”æ¡ˆæˆ–åŸæª”æ¡ˆï¼‰
    """
    try:
        from PIL import Image

        with Image.open(file_path) as img:
            width, height = img.size
            max_dim = max(width, height)

            if max_dim <= max_side:
                print(f"åœ–ç‰‡å¤§å° {width}x{height} åœ¨é™åˆ¶å…§ï¼Œä¸éœ€è¦ç¸®å°")
                return file_path

            # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
            scale = max_side / max_dim
            new_width = int(width * scale)
            new_height = int(height * scale)

            print(f"åœ–ç‰‡å¤ªå¤§ ({width}x{height})ï¼Œç¸®å°ç‚º {new_width}x{new_height}")

            # ç¸®å°åœ–ç‰‡
            resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

            # å„²å­˜åˆ°æ–°æª”æ¡ˆ
            path = Path(file_path)
            new_path = path.parent / f"{path.stem}_resized{path.suffix}"
            resized_img.save(str(new_path), quality=95)

            print(f"ç¸®å°å¾Œåœ–ç‰‡å·²å„²å­˜: {new_path}")
            return str(new_path)

    except Exception as e:
        print(f"ç¸®å°åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ï¼Œä½¿ç”¨åŸå§‹åœ–ç‰‡")
        return file_path


class OCRRequest(BaseModel):
    """OCRè¯·æ±‚æ¨¡å‹"""

    mode: str = "hybrid"
    dpi: int = 200
    lang: str = "ch"


class TaskResponse(BaseModel):
    """ä»»åŠ¡å“åº”æ¨¡å‹"""

    task_id: str
    status: str
    message: str


class OCRResult(BaseModel):
    """OCRç»“æœæ¨¡å‹"""

    task_id: str
    status: str
    progress: float
    results: Optional[Any] = None
    error: Optional[str] = None


from paddleocr_toolkit.core.ocr_cache import ocr_cache
from paddleocr_toolkit.processors.parallel_pdf_processor import ParallelPDFProcessor

# åˆå§‹åŒ–å¹³è¡Œè™•ç†å™¨
parallel_processor = ParallelPDFProcessor()


async def process_ocr_task(
    task_id: str,
    file_path: str,
    mode: str,
    gemini_key: str = None,
    claude_key: str = None,
):
    """
    éåŒæ­¥è™•ç† OCR ä»»å‹™
    """
    # è©³ç´°æ—¥èªŒï¼šä»»å‹™é–‹å§‹
    print("=" * 60)
    print(f"[OCR] é–‹å§‹è™•ç†ä»»å‹™")
    print(f"[OCR] ä»»å‹™ ID: {task_id}")
    print(f"[OCR] æª”æ¡ˆè·¯å¾‘: {file_path}")
    print(f"[OCR] OCR æ¨¡å¼: {mode}")
    print(f"[OCR] Gemini Key: {'å·²æä¾›' if gemini_key else 'æœªæä¾›'}")
    print(f"[OCR] Claude Key: {'å·²æä¾›' if claude_key else 'æœªæä¾›'}")
    print("=" * 60)
    
    tasks[task_id] = {
        "status": "processing",
        "progress": 0,
        "created_at": datetime.now()
    }
    processed_path = str(Path(file_path))
    print(f"[OCR] è™•ç†è·¯å¾‘: {processed_path}")

    try:
        # ... (å¿«å–èˆ‡è™•ç†é‚è¼¯)
        # 0. æª¢æŸ¥å¿«å–
        await manager.send_progress_update(task_id, 5, "processing", "æª¢æŸ¥å¿«å–...")
        cached_result = ocr_cache.get(processed_path, mode)
        if cached_result:
            await manager.send_progress_update(task_id, 100, "completed", "å¿«å–å‘½ä¸­")
            results[task_id] = {
                "status": "completed",
                "progress": 100,
                "results": cached_result,
            }
            tasks[task_id] = {"status": "completed", "progress": 100}
            await manager.send_completion(task_id, cached_result)
            return

        # 1. é è™•ç†åœ–ç‰‡
        actual_path = processed_path
        if processed_path.lower().endswith((".jpg", ".jpeg", ".png", ".bmp", ".webp")):
            await manager.send_progress_update(task_id, 10, "processing", "é è™•ç†åœ–ç‰‡...")
            actual_path = await asyncio.to_thread(
                resize_image_if_needed, processed_path
            )

        # 2. åŸ·è¡Œé æ¸¬
        ext = Path(processed_path).suffix.lower()
        if ext == ".pdf":
            # PDF ä½¿ç”¨ä¸¦è¡Œè™•ç†å™¨
            await manager.send_progress_update(
                task_id, 30, "processing", "PDF ä¸¦è¡Œè¾¨è­˜ä¸­..."
            )
            ocr_result = await asyncio.to_thread(
                parallel_processor.process_pdf_parallel, actual_path, {"mode": mode}
            )
        else:
            # æ¨™æº–å–®é»è¾¨è­˜
            await manager.send_progress_update(task_id, 30, "processing", "æ­£åœ¨è¾¨è­˜...")

            def run_ocr():
                eng = OCREngineManager(
                    mode=mode, device="cpu", plugin_loader=plugin_loader
                )
                eng.init_engine()
                res = eng.predict(actual_path)
                eng.close()
                return res

            ocr_result = await asyncio.to_thread(run_ocr)

        # 3. è™•ç†èˆ‡æ ¡æ­£çµæœ
        await manager.send_progress_update(task_id, 80, "processing", "è™•ç†è¾¨è­˜æ–‡æœ¬...")

        # æå–æ–‡å­—å…§å®¹
        text_content = ""
        if isinstance(ocr_result, list):
            pages_texts = []
            for page in ocr_result:
                if isinstance(page, list):
                    # PaddleOCR æ¨™æº–æ ¼å¼: [[[box], [text, score]], ...]
                    line_texts = []
                    for line in page:
                        if isinstance(line, (list, tuple)) and len(line) >= 2:
                            if isinstance(line[1], (list, tuple)) and len(line[1]) >= 1:
                                line_texts.append(str(line[1][0]))
                        elif isinstance(line, dict):
                            # PaddleX å­—å…¸æ ¼å¼ (åœ¨åˆ—è¡¨å…§)
                            if "rec_texts" in line:
                                line_texts.extend([str(t) for t in line["rec_texts"]])
                            elif "text" in line:
                                line_texts.append(str(line["text"]))

                    pages_texts.append("\n".join(line_texts))

                elif isinstance(page, dict):
                    # PPStructure or newer PaddleOCR format
                    # 1. Check for 'res' (PPStructure standard)
                    if "res" in page and isinstance(page["res"], list):
                        page_text_parts = []
                        for region in page["res"]:
                            if isinstance(region, dict) and "text" in region:
                                page_text_parts.append(region["text"])
                            elif isinstance(region, str):
                                page_text_parts.append(region)
                        pages_texts.append("\n".join(page_text_parts))

                    # 2. Check for 'rec_texts' (PaddleOCR Direct Result / Parallel Processor)
                    elif "rec_texts" in page and isinstance(page["rec_texts"], list):
                        pages_texts.append(
                            "\n".join([str(t) for t in page["rec_texts"]])
                        )

                    # 3. Check for 'text' or 'rec_text' (Single String)
                    elif "text" in page:
                        pages_texts.append(str(page["text"]))
                    elif "rec_text" in page:
                        pages_texts.append(str(page["rec_text"]))

                    # Fallback
                    else:
                        pages_texts.append(str(page))
                else:
                    pages_texts.append(str(page))
            text_content = "\n\n".join(pages_texts)
        else:
            text_content = str(ocr_result)

        # èªç¾©æ ¡æ­£ (Gemini / Claude)
        current_text = text_content
        for provider in ["gemini", "claude"]:
            if provider in mode.lower():
                await manager.send_progress_update(
                    task_id, 90, "processing", f"{provider.capitalize()} æ™ºæ…§å‹˜èª¤ä¸­..."
                )
                try:
                    import os

                    from paddleocr_toolkit.llm.llm_client import create_llm_client

                    # å„ªå…ˆä½¿ç”¨å‚³å…¥çš„é‡‘é‘°ï¼Œæ¬¡ä¹‹ä½¿ç”¨ç’°å¢ƒè®Šæ•¸
                    passed_key = gemini_key if provider == "gemini" else claude_key
                    api_key = passed_key or os.environ.get(
                        f"{provider.upper()}_API_KEY"
                    )

                    if api_key:
                        llm = create_llm_client(provider, api_key=api_key)
                        prompt = (
                            f"è«‹ä¿®æ­£ä»¥ä¸‹ OCR è¾¨è­˜çµæœä¸­çš„éŒ¯èª¤ï¼Œåƒ…é€²è¡Œå‹˜èª¤èˆ‡æ’ç‰ˆä¿®å¾©ï¼š\n\n{text_content[:2500]}"
                        )
                        corrected = await asyncio.to_thread(llm.generate, prompt)
                        if corrected:
                            current_text = corrected
                except Exception as e:
                    print(f"{provider} æ ¡æ­£å¤±æ•—: {e}")

        final_result = {
            "raw_result": current_text,
            "pages": len(ocr_result) if isinstance(ocr_result, list) else 1,
            "confidence": 0.95,
        }

        # 4. å­˜å…¥å¿«å–èˆ‡å®Œæˆ
        ocr_cache.set(processed_path, mode, final_result)
        results[task_id] = {
            "status": "completed",
            "progress": 100,
            "results": final_result,
        }
        tasks[task_id] = {"status": "completed", "progress": 100}
        await manager.send_completion(task_id, final_result)

    except Exception as e:
        error_msg = str(e)
        results[task_id] = {"status": "failed", "progress": 0, "error": error_msg}
        tasks[task_id] = {"status": "failed", "progress": 0}
        results[task_id] = {
            "status": "failed",
            "progress": 0,
            "error": error_msg
        }
        await manager.send_error(task_id, error_msg)
        
        # è©³ç´°éŒ¯èª¤æ—¥èªŒ
        print("=" * 60)
        print(f"[ERROR] ä»»å‹™å¤±æ•—: {task_id}")
        print(f"[ERROR] éŒ¯èª¤è¨Šæ¯: {e}")
        print(f"[ERROR] å®Œæ•´ Traceback:")
        import traceback
        traceback.print_exc()
        print("=" * 60)


@app.get("/", response_class=HTMLResponse)
async def root():
    """æä¾›ç”¨æˆ¶å‹å¥½çš„ Web ä»‹é¢"""
    index_file = WEB_DIR / "index.html"
    if index_file.exists():
        return HTMLResponse(content=index_file.read_text(encoding="utf-8"))
    return HTMLResponse(
        content="""
        <h1>PaddleOCR Toolkit API</h1>
        <p>Version: 1.2.0</p>
        <p><a href="/docs">API æ–‡ä»¶</a></p>
    """
    )


@app.post("/api/ocr", response_model=TaskResponse)
async def upload_and_ocr(
    request: Request,
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks = None,  # type: ignore[assignment]
    mode: str = "hybrid",
    gemini_key: str = Query(None),
    claude_key: str = Query(None),
):
    """
    ä¸Šä¼ æ–‡ä»¶å¹¶è¿›è¡ŒOCRå¤„ç†

    Args:
        file: ä¸Šä¼ çš„æ–‡ä»¶
        background_tasks: åå°ä»»åŠ¡
        mode: OCRæ¨¡å¼

    Returns:
        ä»»åŠ¡IDå’ŒçŠ¶æ€
    """
    # é€Ÿç‡é™åˆ¶æª¢æŸ¥
    client_ip = request.client.host
    if not check_rate_limit(client_ip, RATE_LIMIT):
        raise HTTPException(
            status_code=429,
            detail="è«‹æ±‚éæ–¼é »ç¹ï¼Œè«‹ç¨å¾Œå†è©¦ï¼ˆé™åˆ¶ï¼š10 æ¬¡/åˆ†é˜ï¼‰"
        )
    
    # ç”Ÿæˆä»»åŠ¡ID
    task_id = str(uuid.uuid4())
    print(f"[UPLOAD] æ”¶åˆ°ä¸Šå‚³è«‹æ±‚")
    print(f"[UPLOAD] ä»»å‹™ ID: {task_id}")
    print(f"[UPLOAD] æª”æ¡ˆåç¨±: {file.filename}")
    print(f"[UPLOAD] OCR æ¨¡å¼: {mode}")

    # ä¿å­˜æ–‡ä»¶
    file_path = UPLOAD_DIR / f"{task_id}_{file.filename}"
    with open(file_path, "wb") as f:
        content = await file.read()
        f.write(content)
    
    print(f"[UPLOAD] æª”æ¡ˆå·²å„²å­˜: {file_path}")
    print(f"[UPLOAD] æª”æ¡ˆå¤§å°: {len(content)} bytes")

    # åˆ›å»ºåå°ä»»åŠ¡
    background_tasks.add_task(
        process_ocr_task, task_id, str(file_path), mode, gemini_key, claude_key
    )
    print(f"[UPLOAD] èƒŒæ™¯ä»»å‹™å·²æ’ç¨‹: {task_id}")

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    tasks[task_id] = {"status": "queued", "progress": 0}
    print(f"[UPLOAD] ä»»å‹™ç‹€æ…‹å·²åˆå§‹åŒ–: queued")

    return TaskResponse(task_id=task_id, status="queued", message="ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨å¤„ç†...")


@app.get("/api/tasks/{task_id}", response_model=OCRResult)
async def get_task_status(task_id: str):
    """
    è·å–ä»»åŠ¡çŠ¶æ€

    Args:
        task_id: ä»»åŠ¡ID

    Returns:
        ä»»åŠ¡çŠ¶æ€å’Œç»“æœ
    """
    if task_id not in tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    task_info = tasks[task_id]

    # å¦‚æœä»»åŠ¡å®Œæˆï¼Œè¿”å›ç»“æœ
    if task_id in results:
        return OCRResult(**results[task_id], task_id=task_id)

    # å¦åˆ™è¿”å›å½“å‰çŠ¶æ€
    return OCRResult(
        task_id=task_id, status=task_info["status"], progress=task_info["progress"]
    )


@app.get("/api/results/{task_id}")
async def get_results(task_id: str):
    """
    è·å–OCRç»“æœ

    Args:
        task_id: ä»»åŠ¡ID

    Returns:
        OCRç»“æœ
    """
    if task_id not in results:
        raise HTTPException(status_code=404, detail="ç»“æœä¸å­˜åœ¨")

    return results[task_id]


@app.delete("/api/tasks/{task_id}")
async def delete_task(task_id: str):
    """åˆ é™¤ä»»åŠ¡"""
    if task_id in tasks:
        del tasks[task_id]
    if task_id in results:
        del results[task_id]

    return {"message": "ä»»åŠ¡å·²åˆ é™¤"}


class TranslationRequest(BaseModel):
    text: str
    target_lang: str = "en"
    provider: str = "ollama"
    api_key: Optional[str] = None
    model: Optional[str] = None


class ConvertRequest(BaseModel):
    task_id: str
    target_format: str
    include_metadata: bool = True


@app.get("/api/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡"""
    return {
        "total_tasks": len(tasks),
        "completed_tasks": sum(1 for t in tasks.values() if t["status"] == "completed"),
        "queued_tasks": sum(1 for t in tasks.values() if t["status"] == "queued"),
        "processing_tasks": sum(
            1 for t in tasks.values() if t["status"] == "processing"
        ),
    }


@app.get("/api/files")
async def list_files():
    """åˆ—å‡ºæ‰€æœ‰ä¸Šå‚³çš„æª”æ¡ˆ"""
    files = []
    if UPLOAD_DIR.exists():
        for f in UPLOAD_DIR.iterdir():
            if f.is_file():
                stat = f.stat()
                files.append(
                    {
                        "name": f.name,
                        "size": stat.st_size,
                        "created_at": stat.st_ctime,
                        "modified_at": stat.st_mtime,
                    }
                )
    return files


@app.delete("/api/files/{filename}")
async def delete_file(filename: str):
    """åˆªé™¤æª”æ¡ˆ"""
    file_path = UPLOAD_DIR / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="æª”æ¡ˆä¸å­˜åœ¨")

    try:
        os.remove(file_path)
        return {"message": f"æª”æ¡ˆ {filename} å·²åˆªé™¤"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆªé™¤å¤±æ•—: {str(e)}")


@app.get("/api/files/{filename}/download")
async def download_file(filename: str):
    """ä¸‹è¼‰æª”æ¡ˆ"""
    file_path = UPLOAD_DIR / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="æª”æ¡ˆä¸å­˜åœ¨")

    return FileResponse(
        path=file_path, filename=filename, media_type="application/octet-stream"
    )


@app.get("/api/plugins")
async def list_plugins():
    """åˆ—å‡ºæ‰€æœ‰æ’ä»¶"""
    return plugin_loader.list_plugins()


@app.post("/api/export")
async def export_results(
    data: dict,  # æ¥æ”¶ { "text": "...", "format": "docx", "filename": "..." }
):
    """
    å°‡è¾¨è­˜çµæœåŒ¯å‡ºç‚ºæŒ‡å®šæ ¼å¼çš„æª”æ¡ˆ
    """
    text = data.get("text", "")
    out_format = data.get("format", "docx").lower()
    base_name = data.get("filename", "ocr_result")

    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    try:
        if out_format == "docx":
            from docx import Document

            doc = Document()
            doc.add_heading("OCR è¾¨è­˜çµæœå ±å‘Š", 0)
            doc.add_paragraph(text)
            out_file = OUTPUT_DIR / f"{base_name}_{int(time.time())}.docx"
            doc.save(str(out_file))

        elif out_format == "xlsx":
            from openpyxl import Workbook

            wb = Workbook()
            ws = wb.active
            ws.title = "OCR Result"
            # æŒ‰è¡Œåˆ†å‰²å…§å®¹å¯«å…¥ Excel
            lines = text.split("\n")
            for idx, line in enumerate(lines):
                ws.cell(row=idx + 1, column=1, value=line)
            out_file = OUTPUT_DIR / f"{base_name}_{int(time.time())}.xlsx"
            wb.save(str(out_file))

        elif out_format == "txt":
            # æ–°å¢ç´”æ–‡å­—åŒ¯å‡º
            out_file = OUTPUT_DIR / f"{base_name}_{int(time.time())}.txt"
            out_file.write_text(text, encoding="utf-8")

        else:
            return {"status": "error", "message": f"ä¸æ”¯æ´çš„æ ¼å¼: {out_format}"}

        return {
            "status": "success",
            "download_url": f"/api/files/download/{out_file.name}?directory=output",
            "filename": out_file.name
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.get("/api/export-text/{task_id}")
async def export_text(task_id: str):
    """
    åŒ¯å‡ºä»»å‹™çš„ OCR çµæœç‚ºç´”æ–‡å­—æª”æ¡ˆ
    
    Args:
        task_id: ä»»å‹™ ID
    
    Returns:
        FileResponse: å¯ä¸‹è¼‰çš„æ–‡å­—æª”æ¡ˆ
    """
    if task_id not in results:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    task_result = results[task_id]
    if task_result.get("status") != "completed":
        raise HTTPException(status_code=400, detail="ä»»å‹™å°šæœªå®Œæˆ")
    
    # ç²å–æ–‡å­—å…§å®¹
    text_content = task_result.get("results", {}).get("raw_result", "")
    
    # ç”Ÿæˆæ–‡å­—æª”æ¡ˆ
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    output_file = OUTPUT_DIR / f"ocr_result_{task_id}_{int(time.time())}.txt"
    output_file.write_text(text_content, encoding="utf-8")
    
    # RFC 5987 ç·¨ç¢¼æª”å
    final_filename = "ocr_result.txt"
    encoded_filename = quote(final_filename)

    return FileResponse(
        path=output_file,
        filename=final_filename,
        media_type="text/plain; charset=utf-8",
        headers={
            "Content-Disposition": f"attachment; filename*=utf-8''{encoded_filename}"
        }
    )


@app.post("/api/translate")
async def translate_text(request: TranslationRequest):
    """
    ä½¿ç”¨ AI ç¿»è­¯æ–‡å­—
    
    Args:
        request: ç¿»è­¯è«‹æ±‚ç‰©ä»¶
    
    Returns:
        ç¿»è­¯å¾Œçš„æ–‡å­—
    """
    text = request.text
    target_lang = request.target_lang
    provider = request.provider
    api_key = request.api_key
    model = request.model
    
    print(f"[DEBUG] é–‹å§‹è™•ç†ç¿»è­¯è«‹æ±‚. æä¾›å•†: {provider}, ç›®æ¨™èªè¨€: {target_lang}")
    print(f"[DEBUG] æ–‡å­—é•·åº¦: {len(text)} å­—å…ƒ")
    
    try:
        print("[DEBUG] æ­£åœ¨å°å…¥ LLM å®¢æˆ¶ç«¯...")
        from paddleocr_toolkit.llm.llm_client import create_llm_client
        print("[DEBUG] å°å…¥æˆåŠŸ")
        
        # è¨­å®šæç¤ºè©
        print("[DEBUG] æ­£åœ¨æº–å‚™æç¤ºè©...")
        lang_map = {
            "en": "English",
            "zh-TW": "Traditional Chinese (ç¹é«”ä¸­æ–‡)",
            "zh-CN": "Simplified Chinese (ç®€ä½“ä¸­æ–‡)",
            "ja": "Japanese (æ—¥æœ¬èª)",
            "ko": "Korean (í•œêµ­ì–´)",
            "es": "Spanish",
            "fr": "French",
            "de": "German"
        }
        
        target_language = lang_map.get(target_lang, target_lang)
        prompt = f"""è«‹å°‡ä»¥ä¸‹æ–‡å­—ç¿»è­¯æˆ {target_language}ã€‚
åªéœ€è¦è¼¸å‡ºç¿»è­¯çµæœï¼Œä¸è¦æœ‰ä»»ä½•é¡å¤–èªªæ˜ã€‚

åŸæ–‡ï¼š
{text}

ç¿»è­¯ï¼š"""
        
        print(f"[DEBUG] æç¤ºè©æº–å‚™å®Œæˆ. ç›®æ¨™èªè¨€åç¨±: {target_language}")
        
        # å‰µå»º LLM å®¢æˆ¶ç«¯
        print(f"[DEBUG] æ­£åœ¨å‰µå»º {provider} å®¢æˆ¶ç«¯...")
        kwargs = {}
        if api_key:
            kwargs["api_key"] = api_key
        if model:
            kwargs["model"] = model
        elif provider == "ollama":
            kwargs["model"] = "qwen2.5:7b"
            kwargs["base_url"] = "http://localhost:11434"
        
        llm = create_llm_client(provider=provider, **kwargs)
        print(f"[DEBUG] å®¢æˆ¶ç«¯å‰µå»ºæˆåŠŸ")
        
        # æª¢æŸ¥æœå‹™æ˜¯å¦å¯ç”¨
        print(f"[DEBUG] æ­£åœ¨æª¢æŸ¥ {provider} æœå‹™å¯ç”¨æ€§...")
        if not llm.is_available():
            print(f"[ERROR] {provider} æœå‹™æª¢æŸ¥å¤±æ•— (ä¸å¯ç”¨)")
            return {
                "status": "error",
                "message": f"{provider} æœå‹™ä¸å¯ç”¨ï¼Œè«‹ç¢ºèªå·²å•Ÿå‹•ç›¸é—œæœå‹™"
            }
        
        print(f"[DEBUG] æœå‹™å¯ç”¨æ€§æª¢æŸ¥é€šé")
        
        # ç”Ÿæˆç¿»è­¯
        print(f"[DEBUG] æ­£åœ¨å‘ {provider} ç™¼é€ç”Ÿæˆè«‹æ±‚ (æ­¤æ­¥é©Ÿå¯èƒ½éœ€è¦ä¸€æ®µæ™‚é–“)...")
        translated = llm.generate(prompt, temperature=0.3, max_tokens=4096)
        print(f"[DEBUG] ç”Ÿæˆè«‹æ±‚å®Œæˆ")
        
        if not translated:
            print(f"[WARNING] ç¿»è­¯çµæœç‚ºç©º")
            return {
                "status": "error",
                "message": "ç¿»è­¯å¤±æ•—ï¼Œè«‹é‡è©¦"
            }
        
        print(f"[SUCCESS] ç¿»è­¯å®Œæˆï¼Œé•·åº¦: {len(translated)}")
        return {
            "status": "success",
            "translated_text": translated,
            "provider": provider,
            "target_lang": target_lang
        }
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[ERROR] ç¿»è­¯éŒ¯èª¤: {e}")
        print(error_detail)
        return {
            "status": "error",
            "message": f"ç¿»è­¯å¤±æ•—: {str(e)}"
        }


@app.post("/api/convert")
async def convert_format(request: ConvertRequest):
    """
    å°‡ OCR çµæœè½‰æ›ç‚ºæŒ‡å®šæ ¼å¼
    
    Args:
        request: è½‰æ›è«‹æ±‚ç‰©ä»¶
    
    Returns:
        FileResponse: å¯ä¸‹è¼‰çš„è½‰æ›æª”æ¡ˆ
    """
    task_id = request.task_id
    target_format = request.target_format
    include_metadata = request.include_metadata
    
    if task_id not in results:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    task_result = results[task_id]
    if task_result.get("status") != "completed":
        raise HTTPException(status_code=400, detail="ä»»å‹™å°šæœªå®Œæˆ")
    
    text_content = task_result.get("results", {}).get("raw_result", "")
    
    # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆ
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    timestamp = int(time.time())
    
    try:
        from paddleocr_toolkit.utils.format_converter import FormatConverter
        
        converter = FormatConverter()
        
        if target_format == "docx":
            output_file = OUTPUT_DIR / f"ocr_result_{task_id}_{timestamp}.docx"
            converter.text_to_docx(text_content, str(output_file))
            media_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        
        elif target_format == "xlsx":
            output_file = OUTPUT_DIR / f"ocr_result_{task_id}_{timestamp}.xlsx"
            converter.text_to_xlsx(text_content, str(output_file))
            media_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        
        elif target_format == "pdf":
            output_file = OUTPUT_DIR / f"ocr_result_{task_id}_{timestamp}.pdf"
            converter.text_to_pdf_searchable(text_content, str(output_file))
            media_type = "application/pdf"
        
        elif target_format == "md":
            output_file = OUTPUT_DIR / f"ocr_result_{task_id}_{timestamp}.md"
            metadata = None
            if include_metadata:
                metadata = {
                    "date": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "pages": task_result.get("results", {}).get("pages", 1),
                    "confidence": task_result.get("results", {}).get("confidence", 0.95)
                }
            converter.text_to_markdown(text_content, str(output_file), metadata)
            media_type = "text/markdown; charset=utf-8"
        
        else:  # txt (å‘å¾Œå…¼å®¹)
            output_file = OUTPUT_DIR / f"ocr_result_{task_id}_{timestamp}.txt"
            output_file.write_text(text_content, encoding="utf-8")
            media_type = "text/plain; charset=utf-8"
        
        # RFC 5987 ç·¨ç¢¼æª”å
        final_filename = f"ocr_result.{target_format}"
        encoded_filename = quote(final_filename)

        return FileResponse(
            path=output_file,
            filename=final_filename,
            media_type=media_type,
            headers={
                "Content-Disposition": f"attachment; filename*=utf-8''{encoded_filename}"
            }
        )
    
    except Exception as e:
        print(f"æ ¼å¼è½‰æ›å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"è½‰æ›å¤±æ•—: {str(e)}")


@app.websocket("/ws/{task_id}")
async def websocket_endpoint(websocket: WebSocket, task_id: str):
    """
    WebSocket endpoint for real-time task updates
    """
    await manager.connect(websocket, task_id)
    try:
        while True:
            # Keep connection alive and listen for client messages if needed
            # For now, we just push updates from server
            data = await websocket.receive_text()
            # Optional: handle client commands
            if data == "ping":
                await manager.send_personal_message({"type": "pong"}, websocket)
    except WebSocketDisconnect:
        manager.disconnect(websocket, task_id)
    except Exception as e:
        print(f"WebSocket error: {e}")
        manager.disconnect(websocket, task_id)


if __name__ == "__main__":
    import uvicorn

    print(
        """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                       â•‘
    â•‘     PaddleOCR Toolkit API Server                     â•‘
    â•‘     v3.3.0                                           â•‘
    â•‘                                                       â•‘
    â•‘     Dashboard: http://localhost:8000/                â•‘
    â•‘     Docs:      http://localhost:8000/docs            â•‘
    â•‘                                                       â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    å•Ÿå‹•ä¼ºæœå™¨...
    """
    )
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")


@app.get("/api/export-searchable-pdf/{task_id}")
async def export_searchable_pdf(task_id: str):
    """
    å°‡ OCR çµæœåµŒå…¥åŸå§‹ PDFï¼Œç”Ÿæˆå¯æœå°‹ PDF
    
    Args:
        task_id: ä»»å‹™ ID
    
    Returns:
        FileResponse: å¯ä¸‹è¼‰çš„å¯æœå°‹ PDF æª”æ¡ˆ
    """
    if task_id not in results:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    task_result = results[task_id]
    if task_result.get("status") != "completed":
        raise HTTPException(status_code=400, detail="ä»»å‹™å°šæœªå®Œæˆ")
    
    # ç²å–åŸå§‹æª”æ¡ˆè·¯å¾‘
    original_file = task_result.get("file_path")
    if not original_file or not Path(original_file).exists():
        raise HTTPException(status_code=404, detail="åŸå§‹æª”æ¡ˆä¸å­˜åœ¨")
    
    # åªæ”¯æ´ PDF æª”æ¡ˆ
    if not original_file.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="åƒ…æ”¯æ´ PDF æª”æ¡ˆ")
    
    try:
        import fitz  # PyMuPDF
        
        # ç²å– OCR çµæœ
        ocr_results = task_result.get("results", {})
        raw_result = ocr_results.get("raw_result")
        
        # é–‹å•ŸåŸå§‹ PDF
        doc = fitz.open(original_file)
        
        # å¢å¼·ç‰ˆï¼šä½¿ç”¨ OCR åº§æ¨™è³‡è¨Šé€²è¡Œç²¾ç¢ºå®šä½
        if raw_result and isinstance(raw_result, list):
            # PaddleOCR æ ¼å¼ï¼š[[page1_results], [page2_results], ...]
            for page_idx, page_ocr in enumerate(raw_result):
                if page_idx >= len(doc):
                    break
                
                page = doc[page_idx]
                page_rect = page.rect
                page_height = page_rect.height
                page_width = page_rect.width
                
                if not page_ocr:
                    continue
                
                # è™•ç†æ¯å€‹æ–‡å­—å€å¡Š
                for line in page_ocr:
                    if not line or len(line) < 2:
                        continue
                    
                    # line[0] = åº§æ¨™, line[1] = (æ–‡å­—, ä¿¡å¿ƒåº¦)
                    coords = line[0]  # [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                    text_info = line[1]  # (text, confidence)
                    
                    if not coords or not text_info:
                        continue
                    
                    text = text_info[0] if isinstance(text_info, (tuple, list)) else str(text_info)
                    
                    if not text.strip():
                        continue
                    
                    # è¨ˆç®—é‚Šç•Œæ¡†
                    try:
                        x_coords = [p[0] for p in coords]
                        y_coords = [p[1] for p in coords]
                        x1, x2 = min(x_coords), max(x_coords)
                        y1, y2 = min(y_coords), max(y_coords)
                        
                        # è¨ˆç®—å­—é«”å¤§å°ï¼ˆåŸºæ–¼é«˜åº¦ï¼‰
                        height = y2 - y1
                        font_size = max(1, int(height * 0.8))  # ç¨å¾®å°ä¸€é»ä»¥ç¢ºä¿ä¸æº¢å‡º
                        
                        # æ’å…¥é€æ˜æ–‡å­—ï¼ˆä½¿ç”¨ insert_text è€Œé insert_textboxï¼‰
                        # ä½ç½®ä½¿ç”¨å·¦ä¸‹è§’åº§æ¨™
                        try:
                            page.insert_text(
                                (x1, y2),
                                text,
                                fontsize=font_size,
                                color=(1, 1, 1),  # ç™½è‰²ï¼ˆä¸å¯è¦‹ï¼‰
                                overlay=False
                            )
                        except:
                            # å¦‚æœæ’å…¥å¤±æ•—ï¼Œå˜—è©¦ç”¨æ›´å°çš„å­—é«”
                            page.insert_text(
                                (x1, y2),
                                text,
                                fontsize=max(1, font_size // 2),
                                color=(1, 1, 1),
                                overlay=False
                            )
                    except (IndexError, ValueError, TypeError) as e:
                        # åº§æ¨™æ ¼å¼ä¸æ­£ç¢ºï¼Œè·³éé€™å€‹å€å¡Š
                        continue
        else:
            # é™ç´šæ–¹æ¡ˆï¼šå¦‚æœæ²’æœ‰åº§æ¨™è³‡è¨Šï¼Œä½¿ç”¨èˆŠæ–¹æ³•
            raw_text = ocr_results.get("raw_result", "")
            if isinstance(raw_text, str) and raw_text and len(doc) > 0:
                page = doc[0]
                rect = page.rect
                try:
                    page.insert_textbox(
                        rect,
                        raw_text,
                        fontsize=1,
                        color=(1, 1, 1),
                        overlay=False
                    )
                except:
                    pass
        
        # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆ
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        output_file = OUTPUT_DIR / f"searchable_{task_id}_{int(time.time())}.pdf"
        doc.save(str(output_file))
        doc.close()
        
        # RFC 5987 ç·¨ç¢¼æª”å
        final_filename = "searchable_ocr_result.pdf"
        encoded_filename = quote(final_filename)
        
        return FileResponse(
            path=output_file,
            filename=final_filename,
            media_type="application/pdf",
            headers={
                "Content-Disposition": f"attachment; filename*=utf-8''{encoded_filename}"
            }
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¯æœå°‹ PDF å¤±æ•—: {str(e)}")


# ==================== æ‰¹é‡è™•ç† API ====================

@app.post("/api/batch-ocr")
async def batch_ocr(
    request: Request,
    files: list[UploadFile] = File(...),
    background_tasks: BackgroundTasks = None,
    mode: str = "basic",
    gemini_key: Optional[str] = None,
    claude_key: Optional[str] = None
):
    """
    æ‰¹é‡è™•ç†å¤šå€‹ PDF/åœ–ç‰‡æª”æ¡ˆ
    
    Args:
        files: ä¸Šå‚³çš„æª”æ¡ˆåˆ—è¡¨
        mode: OCR æ¨¡å¼ (basic, hybrid, structure ç­‰)
        gemini_key: Gemini API Keyï¼ˆå¯é¸ï¼‰
        claude_key: Claude API Keyï¼ˆå¯é¸ï¼‰
    
    Returns:
        {
            "batch_id": str,
            "task_ids": List[str],
            "total": int
        }
    """
    # é€Ÿç‡é™åˆ¶æª¢æŸ¥ï¼ˆæ‰¹é‡è™•ç†æ›´åš´æ ¼ï¼‰
    client_ip = request.client.host
    if not check_rate_limit(client_ip, RATE_LIMIT_BATCH):
        raise HTTPException(
            status_code=429,
            detail="æ‰¹é‡è™•ç†è«‹æ±‚éæ–¼é »ç¹ï¼Œè«‹ç¨å¾Œå†è©¦ï¼ˆé™åˆ¶ï¼š3 æ¬¡/åˆ†é˜ï¼‰"
        )
    
    if not files:
        raise HTTPException(status_code=400, detail="æœªé¸æ“‡æª”æ¡ˆ")
    
    if len(files) > 20:
        raise HTTPException(status_code=400, detail="ä¸€æ¬¡æœ€å¤šè™•ç† 20 å€‹æª”æ¡ˆ")
    
    batch_id = str(uuid.uuid4())
    task_ids = []
    
    print(f"=" * 60)
    print(f"[BATCH] æ‰¹é‡è™•ç†è«‹æ±‚")
    print(f"[BATCH] Batch ID: {batch_id}")
    print(f"[BATCH] æª”æ¡ˆæ•¸é‡: {len(files)}")
    print(f"[BATCH] OCR æ¨¡å¼: {mode}")
    print(f"=" * 60)
    
    try:
        for idx, file in enumerate(files):
            task_id = str(uuid.uuid4())
            
            # å„²å­˜æª”æ¡ˆ
            file_extension = Path(file.filename).suffix.lower()
            file_path = UPLOAD_DIR / f"{task_id}{file_extension}"
            
            with open(file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            
            print(f"[BATCH] æª”æ¡ˆ {idx+1}/{len(files)}: {file.filename} -> {file_path}")
            
            # å»ºç«‹ä»»å‹™
            tasks[task_id] = {
                "status": "queued",
                "progress": 0,
                "created_at": datetime.now(),
                "batch_id": batch_id,
                "file_name": file.filename
            }
            
            # æ·»åŠ èƒŒæ™¯ä»»å‹™
            background_tasks.add_task(
                process_ocr_task,
                task_id,
                str(file_path),
                mode,
                gemini_key,
                claude_key
            )
            
            task_ids.append(task_id)
        
        # å»ºç«‹æ‰¹é‡è¿½è¹¤
        batches[batch_id] = {
            "task_ids": task_ids,
            "status": "processing",
            "completed": 0,
            "total": len(files),
            "created_at": datetime.now()
        }
        
        print(f"[BATCH] æ‰¹é‡ä»»å‹™å·²å»ºç«‹ï¼Œé–‹å§‹è™•ç†")
        print(f"=" * 60)
        
        return {
            "batch_id": batch_id,
            "task_ids": task_ids,
            "total": len(files)
        }
        
    except Exception as e:
        print(f"[BATCH ERROR] {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡è™•ç†å¤±æ•—: {str(e)}")


@app.get("/api/batch/{batch_id}/status")
async def get_batch_status(batch_id: str):
    """
    æŸ¥è©¢æ‰¹é‡è™•ç†ç‹€æ…‹
    
    Args:
        batch_id: æ‰¹é‡ ID
    
    Returns:
        {
            "batch_id": str,
            "total": int,
            "completed": int,
            "failed": int,
            "processing": int,
            "progress": float,
            "tasks": List[dict]
        }
    """
    if batch_id not in batches:
        raise HTTPException(status_code=404, detail="æ‰¹é‡ä»»å‹™ä¸å­˜åœ¨")
    
    batch = batches[batch_id]
    task_ids = batch["task_ids"]
    
    # æ”¶é›†æ‰€æœ‰ä»»å‹™ç‹€æ…‹
    task_statuses = []
    completed = 0
    failed = 0
    processing = 0
    
    for task_id in task_ids:
        task = tasks.get(task_id, {})
        status = task.get("status", "unknown")
        
        if status == "completed":
            completed += 1
        elif status == "failed":
            failed += 1
        elif status in ["processing", "queued"]:
            processing += 1
        
        task_statuses.append({
            "task_id": task_id,
            "file_name": task.get("file_name", ""),
            "status": status,
            "progress": task.get("progress", 0)
        })
    
    # è¨ˆç®—æ•´é«”é€²åº¦
    progress = (completed / batch["total"] * 100) if batch["total"] > 0 else 0
    
    # æ›´æ–°æ‰¹é‡ç‹€æ…‹
    if completed + failed == batch["total"]:
        batch["status"] = "completed"
    
    return {
        "batch_id": batch_id,
        "total": batch["total"],
        "completed": completed,
        "failed": failed,
        "processing": processing,
        "progress": round(progress, 2),
        "tasks": task_statuses
    }


@app.get("/api/batch/{batch_id}/results")
async def get_batch_results(batch_id: str):
    """
    ç²å–æ‰¹é‡è™•ç†çµæœ
    
    Args:
        batch_id: æ‰¹é‡ ID
    
    Returns:
        {
            "batch_id": str,
            "results": List[dict]
        }
    """
    if batch_id not in batches:
        raise HTTPException(status_code=404, detail="æ‰¹é‡ä»»å‹™ä¸å­˜åœ¨")
    
    batch = batches[batch_id]
    task_ids = batch["task_ids"]
    
    # æ”¶é›†æ‰€æœ‰çµæœ
    batch_results = []
    for task_id in task_ids:
        if task_id in results:
            result = results[task_id]
            batch_results.append({
                "task_id": task_id,
                "file_name": tasks.get(task_id, {}).get("file_name", ""),
                "status": result.get("status", "unknown"),
                "result": result.get("results", {})
            })
    
    return {
        "batch_id": batch_id,
        "results": batch_results
    }


@app.delete("/api/batch/{batch_id}")
async def delete_batch(batch_id: str):
    """
    åˆªé™¤æ‰¹é‡ä»»å‹™åŠç›¸é—œè³‡æ–™
    
    Args:
        batch_id: æ‰¹é‡ ID
    """
    if batch_id not in batches:
        raise HTTPException(status_code=404, detail="æ‰¹é‡ä»»å‹™ä¸å­˜åœ¨")
    
    batch = batches[batch_id]
    task_ids = batch["task_ids"]
    
    # åˆªé™¤æ‰€æœ‰ç›¸é—œä»»å‹™å’Œçµæœ
    for task_id in task_ids:
        if task_id in tasks:
            del tasks[task_id]
        if task_id in results:
            del results[task_id]
    
    # åˆªé™¤æ‰¹é‡è¨˜éŒ„
    del batches[batch_id]
    
    return {"message": f"æ‰¹é‡ä»»å‹™ {batch_id} å·²åˆªé™¤"}
