#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PaddleOCR å·¥å…· - å¤šåŠŸèƒ½æ–‡ä»¶è¾¨è­˜èˆ‡è™•ç†å™¨

æœ¬å·¥å…·ä½¿ç”¨ PaddleOCR 3.x é€²è¡Œæ–‡å­—è­˜åˆ¥ï¼Œæ”¯æ´å¤šç¨® OCR æ¨¡å¼ï¼š
- basic: PP-OCRv5 åŸºæœ¬æ–‡å­—è­˜åˆ¥
- structure: PP-StructureV3 çµæ§‹åŒ–æ–‡ä»¶è§£æï¼ˆä¿ç•™æ’ç‰ˆï¼‰
- vl: PaddleOCR-VL è¦–è¦ºèªè¨€æ¨¡å‹ï¼ˆæ”¯æ´ 109 ç¨®èªè¨€ï¼‰

ä½¿ç”¨æ–¹æ³•:
    # åŸºæœ¬ OCRï¼ˆè¼¸å‡ºæ–‡å­—ï¼‰
    python paddle_ocr_tool.py input.pdf --text-output result.txt
    
    # ç”Ÿæˆå¯æœå°‹ PDF
    python paddle_ocr_tool.py input.pdf --searchable
    
    # PP-StructureV3 æ¨¡å¼ï¼ˆè¼¸å‡º Markdownï¼‰
    python paddle_ocr_tool.py input.pdf --mode structure --markdown-output result.md
    
    # PaddleOCR-VL æ¨¡å¼ï¼ˆè¼¸å‡º JSONï¼‰
    python paddle_ocr_tool.py input.pdf --mode vl --json-output result.json
    
    # å•Ÿç”¨æ–‡ä»¶æ–¹å‘æ ¡æ­£
    python paddle_ocr_tool.py input.pdf --orientation-classify --text-output result.txt
    
    # æ‰¹æ¬¡è™•ç†ç›®éŒ„
    python paddle_ocr_tool.py ./images/ --searchable
"""

import argparse
import os
import sys
import tempfile
import shutil
import logging
import traceback
import gc
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any
from dataclasses import dataclass
from enum import Enum
from datetime import datetime

# åœç”¨æ¨¡å‹ä¾†æºæª¢æŸ¥ä»¥åŠ å¿«å•Ÿå‹•é€Ÿåº¦ï¼ˆå·²æœ‰æœ¬æ©Ÿæ¨¡å‹æ™‚ä¸éœ€è¦é€£ç·šæª¢æŸ¥ï¼‰
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'

# è¨­å®šæ—¥èªŒ
def setup_logging(log_file: Optional[str] = None):
    """è¨­å®šæ—¥èªŒè¨˜éŒ„"""
    if log_file is None:
        log_file = Path(__file__).parent / f"paddle_ocr_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    # ç§»é™¤ç¾æœ‰çš„æ‰€æœ‰ handlers
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # å‰µå»ºæª”æ¡ˆ handler
    file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='w')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))
    
    # å‰µå»ºæ§åˆ¶å° handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))
    
    # è¨­å®š root logger
    logging.root.setLevel(logging.INFO)
    logging.root.addHandler(file_handler)
    logging.root.addHandler(console_handler)
    
    # ç«‹å³å¯«å…¥ç¬¬ä¸€æ¢è¨˜éŒ„
    logging.info(f"=" * 60)
    logging.info(f"æ—¥èªŒæª”æ¡ˆï¼š{log_file}")
    logging.info(f"=" * 60)
    
    # å¼·åˆ¶ flush
    for handler in logging.root.handlers:
        handler.flush()
    
    return log_file

# æª¢æŸ¥ä¾è³´é …
try:
    from paddleocr import PaddleOCR
    # å˜—è©¦å°å…¥é€²éšæ¨¡çµ„ï¼ˆå¯é¸ï¼‰
    try:
        from paddleocr import PPStructureV3
        HAS_STRUCTURE = True
    except ImportError:
        HAS_STRUCTURE = False
    try:
        from paddleocr import PaddleOCRVL
        HAS_VL = True
    except ImportError:
        HAS_VL = False
    try:
        from paddleocr import FormulaRecPipeline
        HAS_FORMULA = True
    except ImportError:
        HAS_FORMULA = False
except ImportError:
    print("éŒ¯èª¤ï¼šè«‹å®‰è£ paddleocr: pip install paddleocr")
    sys.exit(1)

try:
    import fitz  # PyMuPDF
except ImportError:
    print("éŒ¯èª¤ï¼šè«‹å®‰è£ pymupdf: pip install pymupdf")
    sys.exit(1)

try:
    from PIL import Image
    import numpy as np
except ImportError:
    print("éŒ¯èª¤ï¼šè«‹å®‰è£ Pillow å’Œ numpy: pip install Pillow numpy")
    sys.exit(1)

# å¯é¸ä¾è³´ï¼šé€²åº¦æ¢
try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

# å¯é¸ä¾è³´ï¼šExcel è¼¸å‡º
try:
    import openpyxl
    HAS_OPENPYXL = True
except ImportError:
    HAS_OPENPYXL = False

# å¯é¸ä¾è³´ï¼šç¿»è­¯æ¨¡çµ„
try:
    from pdf_translator import (
        OllamaTranslator,
        TextInpainter,
        TextRenderer,
        TranslatedBlock,
        MonolingualPDFGenerator,
        BilingualPDFGenerator
    )
    HAS_TRANSLATOR = True
except ImportError:
    HAS_TRANSLATOR = False
    logging.warning("ç¿»è­¯æ¨¡çµ„ (pdf_translator) æœªå®‰è£ï¼Œç¿»è­¯åŠŸèƒ½ä¸å¯ç”¨")


# OCR æ¨¡å¼æšèˆ‰
class OCRMode(Enum):
    BASIC = "basic"           # PP-OCRv5 åŸºæœ¬æ–‡å­—è­˜åˆ¥
    STRUCTURE = "structure"   # PP-StructureV3 çµæ§‹åŒ–æ–‡ä»¶è§£æ
    VL = "vl"                 # PaddleOCR-VL è¦–è¦ºèªè¨€æ¨¡å‹
    FORMULA = "formula"       # PP-FormulaNet å…¬å¼è­˜åˆ¥
    HYBRID = "hybrid"         # æ··åˆæ¨¡å¼ï¼šç‰ˆé¢åˆ†æ + ç²¾ç¢º OCR


# æ”¯æ´çš„æª”æ¡ˆæ ¼å¼
SUPPORTED_IMAGE_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}
SUPPORTED_PDF_FORMAT = '.pdf'


def fix_english_spacing(text: str) -> str:
    """
    ä¿®å¾©è‹±æ–‡ OCR çµæœä¸­çš„ç©ºæ ¼å•é¡Œ
    
    1. CamelCase åˆ†è©ï¼šFoundryService â†’ Foundry Service
    2. ä¿®å¾©é€£å­—ç¬¦ï¼šwellestablished â†’ well-established
    3. æ•¸å­—å‰å¾Œç©ºæ ¼ï¼šDec.1992and â†’ Dec. 1992 and
    """
    import re
    
    if not text:
        return text
    
    result = text
    
    # ä¿è­·ä¸æ‡‰è©²è¢«æ‹†åˆ†çš„å°ˆæ¥­è¡“èª
    PROTECTED_TERMS = {
        'MUMPs', 'PolyMUMPs', 'SOIMUMPs', 'MetalMUMPs',
        'MEMScAP', 'MEMSCAP', 'MEMSProcesses',
        'PaddleOCR', 'PowerPoint', 'JavaScript', 'TypeScript',
        'GitHub', 'LinkedIn', 'YouTube', 'Facebook',
        'iPhone', 'iPad', 'macOS', 'iOS', 'WiFi',
        'TM', 'PhD', 'CEO', 'CTO', 'CFO',
    }
    
    # å…ˆç”¨ä½”ä½ç¬¦ä¿è­·é€™äº›è©
    protected_map = {}
    for i, term in enumerate(PROTECTED_TERMS):
        if term in result:
            placeholder = f"__PROT_{i}__"
            protected_map[placeholder] = term
            result = result.replace(term, placeholder)
    
    # 1. CamelCase åˆ†è©ï¼ˆå°å¯«å¾Œæ¥å¤§å¯«ï¼‰
    # ä¾‹å¦‚ï¼šFoundryService â†’ Foundry Service
    result = re.sub(r'([a-z])([A-Z])', r'\1 \2', result)
    
    # 1.1 ä¿®å¾©å°å¯«å¾Œæ¥ä½”ä½ç¬¦ï¼ˆä¾‹å¦‚ byMEMScAP â†’ by MEMScAPï¼‰
    result = re.sub(r'([a-z])(__PROT_)', r'\1 \2', result)
    
    # 2. å¤§å¯«å­—æ¯åºåˆ—å¾Œæ¥å°å¯«ï¼ˆä¾‹å¦‚ CMOSMems â†’ CMOS Memsï¼‰
    result = re.sub(r'([A-Z]{2,})([A-Z][a-z])', r'\1 \2', result)
    
    # 3. ä¿®å¾©æ•¸å­—å’Œå­—æ¯ä¹‹é–“ç¼ºå°‘ç©ºæ ¼
    result = re.sub(r'(\d)([a-zA-Z])', r'\1 \2', result)  # æ•¸å­—å¾Œæ¥å­—æ¯
    # å­—æ¯å¾Œæ¥æ•¸å­— - ä½†ä¸æ‹†åˆ†å¦‚ v10, Dec1992 ä¸­çš„é€£æ¥
    result = re.sub(r'([a-z])(\d)', r'\1 \2', result)  # å°å¯«å¾Œæ¥æ•¸å­—
    
    # 4. ä¿®å¾©æ¨™é»ç¬¦è™Ÿå¾Œç¼ºå°‘ç©ºæ ¼
    result = re.sub(r'\.(\d)', r'. \1', result)  # å¥è™Ÿå¾Œæ¥æ•¸å­—
    result = re.sub(r'\.([A-Z])', r'. \1', result)  # å¥è™Ÿå¾Œæ¥å¤§å¯«
    result = re.sub(r',([A-Za-z])', r', \1', result)  # é€—è™Ÿå¾Œæ¥å­—æ¯
    
    # 5. ä¿®å¾©æ‹¬è™Ÿå‰å¾Œç©ºæ ¼
    result = re.sub(r'([a-zA-Z])\(', r'\1 (', result)
    result = re.sub(r'\)([a-zA-Z])', r') \1', result)
    
    # 5.1 ä¿®å¾©å¸¸è¦‹çš„é»é€£è©
    # Aprogramoffered â†’ A program offered
    common_splits = {
        'Aprogram': 'A program',
        'aprogram': 'a program',
        'Theprogram': 'The program',
        'theprogram': 'the program',
        'programoffered': 'program offered',
        'isdesigned': 'is designed',
        'wasestablished': 'was established',
        'hasbeen': 'has been',
        'canbe': 'can be',
        'willbe': 'will be',
        'tobe': 'to be',
        'forthe': 'for the',
        'tothe': 'to the',
        'ofthe': 'of the',
        'inthe': 'in the',
        'onthe': 'on the',
        'bythe': 'by the',
        'andthe': 'and the',
        'isthe': 'is the',
        'asthe': 'as the',
        'withthe': 'with the',
        # æ–°å¢
        'Designof': 'Design of',
        'designof': 'design of',
        'micromachiningby': 'micromachining by',
        'isused': 'is used',
        'areused': 'are used',
        'canbeused': 'can be used',
        'providescustomers': 'provides customers',
        'includesthe': 'includes the',
        'suchas': 'such as',
        'aswellas': 'as well as',
        'inorder': 'in order',
        'orderto': 'order to',
        'dueto': 'due to',
        'byvarious': 'by various',
        'forvarious': 'for various',
        'withcost': 'with cost',
        'tofabricate': 'to fabricate',
        'todesign': 'to design',
        'toannounce': 'to announce',
    }
    for wrong, correct in common_splits.items():
        result = result.replace(wrong, correct)
    
    # 6. ä¿®å¾©å¸¸è¦‹çš„é€£å­—ç¬¦è©
    common_hyphenated = {
        'wellestablished': 'well-established',
        'costeffective': 'cost-effective',
        'highperformance': 'high-performance',
        'lowpower': 'low-power',
        'stateoftheart': 'state-of-the-art',
        'realtime': 'real-time',
        'onchip': 'on-chip',
        'offchip': 'off-chip',
        'multiuser': 'multi-user',
        'Multi User': 'Multi-User',
        'waferlevel': 'wafer-level',
        'Wafer Level': 'Wafer-Level',
    }
    for wrong, correct in common_hyphenated.items():
        result = re.sub(wrong, correct, result, flags=re.IGNORECASE)
    
    # æ¢å¾©è¢«ä¿è­·çš„å°ˆæ¥­è¡“èª
    for placeholder, term in protected_map.items():
        result = result.replace(placeholder, term)
    
    # 7. æ¸…ç†å¤šé¤˜ç©ºæ ¼
    result = re.sub(r' +', ' ', result)
    
    return result


def detect_pdf_quality(pdf_path: str) -> dict:
    """
    åµæ¸¬ PDF å“è³ªï¼Œåˆ¤æ–·æ˜¯å¦ç‚ºæƒæä»¶æˆ–æ¨¡ç³Šæ–‡ä»¶
    
    Returns:
        dict: {
            'is_scanned': bool,      # æ˜¯å¦ç‚ºæƒæä»¶
            'is_blurry': bool,       # æ˜¯å¦æ¨¡ç³Š
            'has_text': bool,        # æ˜¯å¦æœ‰å¯æå–çš„æ–‡å­—
            'recommended_dpi': int,  # å»ºè­°çš„ DPI
            'reason': str            # åˆ¤æ–·åŸå› 
        }
    """
    try:
        import fitz
        
        result = {
            'is_scanned': False,
            'is_blurry': False,
            'has_text': False,
            'recommended_dpi': 150,
            'reason': ''
        }
        
        pdf_doc = fitz.open(pdf_path)
        
        if len(pdf_doc) == 0:
            result['reason'] = 'PDF ç„¡é é¢'
            pdf_doc.close()
            return result
        
        # åªæª¢æŸ¥å‰å¹¾é 
        pages_to_check = min(3, len(pdf_doc))
        total_text_length = 0
        total_images = 0
        
        for page_num in range(pages_to_check):
            page = pdf_doc[page_num]
            
            # æª¢æŸ¥å¯æå–çš„æ–‡å­—
            text = page.get_text("text")
            total_text_length += len(text.strip())
            
            # æª¢æŸ¥åœ–ç‰‡æ•¸é‡
            images = page.get_images()
            total_images += len(images)
        
        pdf_doc.close()
        
        # åˆ¤æ–·é‚è¼¯
        avg_text_per_page = total_text_length / pages_to_check
        avg_images_per_page = total_images / pages_to_check
        
        # å¦‚æœå¹¾ä¹æ²’æœ‰å¯æå–æ–‡å­—ä½†æœ‰åœ–ç‰‡ï¼Œå¾ˆå¯èƒ½æ˜¯æƒæä»¶
        if avg_text_per_page < 50 and avg_images_per_page >= 1:
            result['is_scanned'] = True
            result['recommended_dpi'] = 300
            result['reason'] = f'åµæ¸¬ç‚ºæƒæä»¶ï¼ˆå¹³å‡æ¯é  {avg_text_per_page:.0f} å­—å…ƒï¼Œ{avg_images_per_page:.1f} å¼µåœ–ç‰‡ï¼‰'
        
        # å¦‚æœæœ‰å°‘é‡æ–‡å­—ï¼Œå¯èƒ½æ˜¯éƒ¨åˆ†æƒæ
        elif avg_text_per_page < 200 and avg_images_per_page >= 1:
            result['is_scanned'] = True
            result['is_blurry'] = True
            result['recommended_dpi'] = 200
            result['reason'] = f'åµæ¸¬ç‚ºéƒ¨åˆ†æƒææ–‡ä»¶ï¼ˆå¹³å‡æ¯é  {avg_text_per_page:.0f} å­—å…ƒï¼‰'
        
        # æœ‰è¶³å¤ æ–‡å­—ï¼Œæ˜¯ä¸€èˆ¬ PDF
        else:
            result['has_text'] = True
            result['recommended_dpi'] = 150
            result['reason'] = f'åµæ¸¬ç‚ºä¸€èˆ¬ PDFï¼ˆå¹³å‡æ¯é  {avg_text_per_page:.0f} å­—å…ƒï¼‰'
        
        return result
        
    except Exception as e:
        logging.warning(f"PDF å“è³ªåµæ¸¬å¤±æ•—: {e}")
        return {
            'is_scanned': False,
            'is_blurry': False,
            'has_text': False,
            'recommended_dpi': 150,
            'reason': f'åµæ¸¬å¤±æ•—: {e}'
        }


@dataclass
class OCRResult:
    """OCR è¾¨è­˜çµæœè³‡æ–™çµæ§‹"""
    text: str                    # è¾¨è­˜çš„æ–‡å­—
    confidence: float            # ä¿¡è³´åº¦ (0-1)
    bbox: List[List[float]]      # é‚Šç•Œæ¡†åº§æ¨™ [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
    
    @property
    def x(self) -> float:
        """å·¦ä¸Šè§’ X åº§æ¨™"""
        return min(p[0] for p in self.bbox)
    
    @property
    def y(self) -> float:
        """å·¦ä¸Šè§’ Y åº§æ¨™"""
        return min(p[1] for p in self.bbox)
    
    @property
    def width(self) -> float:
        """é‚Šç•Œæ¡†å¯¬åº¦"""
        xs = [p[0] for p in self.bbox]
        return max(xs) - min(xs)
    
    @property
    def height(self) -> float:
        """é‚Šç•Œæ¡†é«˜åº¦"""
        ys = [p[1] for p in self.bbox]
        return max(ys) - min(ys)


class PDFGenerator:
    """
    PDF ç”Ÿæˆå™¨ - ä½¿ç”¨ Umi-OCR é‚è¼¯å»ºç«‹é›™å±¤å¯æœå°‹ PDF
    
    é€é PyMuPDF åœ¨åŸå§‹åœ–ç‰‡ä¸Šç–ŠåŠ é€æ˜æ–‡å­—å±¤ï¼Œ
    ä½¿ PDF å¯æœå°‹ã€å¯é¸å–æ–‡å­—ï¼ŒåŒæ™‚ä¿æŒåŸå§‹è¦–è¦ºå¤–è§€ã€‚
    """
    
    def __init__(self, output_path: str):
        """
        åˆå§‹åŒ– PDF ç”Ÿæˆå™¨
        
        Args:
            output_path: è¼¸å‡º PDF çš„æª”æ¡ˆè·¯å¾‘
        """
        self.output_path = output_path
        self.doc = fitz.open()  # å»ºç«‹æ–°çš„ç©ºç™½ PDF
        self.page_count = 0
    
    def add_page(self, image_path: str, ocr_results: List[OCRResult]) -> bool:
        """
        æ–°å¢ä¸€é åˆ° PDF
        
        Args:
            image_path: åŸå§‹åœ–ç‰‡è·¯å¾‘
            ocr_results: OCR è¾¨è­˜çµæœåˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ–°å¢é é¢
        """
        try:
            # é–‹å•Ÿåœ–ç‰‡ä»¥å–å¾—å°ºå¯¸
            img = Image.open(image_path)
            img_width, img_height = img.size
            
            # å»ºç«‹æ–°é é¢ï¼Œå°ºå¯¸èˆ‡åœ–ç‰‡ç›¸åŒ
            page = self.doc.new_page(
                width=img_width,
                height=img_height
            )
            
            # æ’å…¥åœ–ç‰‡ä½œç‚ºèƒŒæ™¯
            rect = fitz.Rect(0, 0, img_width, img_height)
            page.insert_image(rect, filename=image_path)
            
            # ç–ŠåŠ é€æ˜æ–‡å­—å±¤
            for result in ocr_results:
                self._insert_invisible_text(page, result)
            
            self.page_count += 1
            return True
            
        except Exception as e:
            print(f"è­¦å‘Šï¼šæ–°å¢é é¢å¤±æ•— ({image_path}): {e}")
            return False
    
    def add_page_from_pixmap(self, pixmap: fitz.Pixmap, ocr_results: List[OCRResult]) -> bool:
        """
        å¾ PyMuPDF Pixmap æ–°å¢ä¸€é åˆ° PDF
        
        Args:
            pixmap: PyMuPDF çš„ Pixmap ç‰©ä»¶
            ocr_results: OCR è¾¨è­˜çµæœåˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ–°å¢é é¢
        """
        try:
            img_width = pixmap.width
            img_height = pixmap.height
            
            # å»ºç«‹æ–°é é¢
            page = self.doc.new_page(
                width=img_width,
                height=img_height
            )
            
            # æ’å…¥ pixmap ä½œç‚ºèƒŒæ™¯
            rect = fitz.Rect(0, 0, img_width, img_height)
            page.insert_image(rect, pixmap=pixmap)
            
            # ç–ŠåŠ é€æ˜æ–‡å­—å±¤
            for result in ocr_results:
                self._insert_invisible_text(page, result)
            
            self.page_count += 1
            return True
            
        except Exception as e:
            print(f"è­¦å‘Šï¼šæ–°å¢é é¢å¤±æ•—: {e}")
            return False
    
    def _insert_invisible_text(self, page: fitz.Page, result: OCRResult) -> None:
        """
        åœ¨é é¢ä¸Šæ’å…¥é€æ˜æ–‡å­—
        
        ä½¿ç”¨ PDF æ¸²æŸ“æ¨¡å¼ 3ï¼ˆéš±å½¢ï¼‰ä¾†ç¢ºä¿æ–‡å­—ä¸å¯è¦‹ä½†å¯é¸å–/æœå°‹
        
        Args:
            page: PyMuPDF é é¢ç‰©ä»¶
            result: OCR è¾¨è­˜çµæœ
        """
        if not result.text.strip():
            return
        
        try:
            # è¨ˆç®—æ–‡å­—å€åŸŸ
            x = result.x
            y = result.y
            width = result.width
            height = result.height
            
            # è¨ˆç®—é©ç•¶çš„å­—é«”å¤§å°ï¼ˆæ ¹æ“šé‚Šç•Œæ¡†é«˜åº¦ï¼‰
            # ä½¿ç”¨ 0.75 å€é«˜åº¦ä½œç‚ºå­—é«”å¤§å°ï¼Œé€™æ˜¯ç¶“é©—å€¼
            font_size = height * 0.75
            if font_size < 1:
                font_size = 1
            
            # å»ºç«‹æ–‡å­—æ’å…¥é»ï¼ˆå·¦ä¸‹è§’ï¼‰
            # PDF çš„æ–‡å­—åŸºç·šåœ¨å·¦ä¸‹è§’
            text_point = fitz.Point(x, y + height * 0.85)
            
            # æ’å…¥é€æ˜æ–‡å­—
            # render_mode=3 è¡¨ç¤ºéš±å½¢æ–‡å­—ï¼ˆä¸æ¸²æŸ“ä½†å¯æœå°‹ï¼‰
            page.insert_text(
                text_point,
                result.text,
                fontsize=font_size,
                fontname="china-s",  # ä½¿ç”¨å…§å»ºä¸­æ–‡å­—é«”
                render_mode=3,  # éš±å½¢æ¨¡å¼
                color=(0, 0, 0)  # é»‘è‰²ï¼ˆé›–ç„¶æ˜¯éš±å½¢çš„ï¼‰
            )
            
        except Exception as e:
            # å¦‚æœä½¿ç”¨ä¸­æ–‡å­—é«”å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨åŸºæœ¬å­—é«”
            try:
                page.insert_text(
                    fitz.Point(result.x, result.y + result.height * 0.85),
                    result.text,
                    fontsize=result.height * 0.75,
                    fontname="helv",
                    render_mode=3,
                    color=(0, 0, 0)
                )
            except Exception as e2:
                print(f"è­¦å‘Šï¼šæ’å…¥æ–‡å­—å¤±æ•— '{result.text[:20]}...': {e2}")
    
    def save(self) -> bool:
        """
        å„²å­˜ PDF æª”æ¡ˆ
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸå„²å­˜
        """
        try:
            if self.page_count == 0:
                print("è­¦å‘Šï¼šæ²’æœ‰é é¢å¯å„²å­˜")
                return False
            
            self.doc.save(self.output_path)
            self.doc.close()
            print(f"âœ“ PDF å·²å„²å­˜ï¼š{self.output_path} ({self.page_count} é )")
            return True
            
        except Exception as e:
            print(f"éŒ¯èª¤ï¼šå„²å­˜ PDF å¤±æ•—: {e}")
            return False


class PaddleOCRTool:
    """
    PaddleOCR å·¥å…·ä¸»é¡åˆ¥
    
    æä¾› OCR æ–‡å­—è¾¨è­˜å’Œå¯æœå°‹ PDF ç”ŸæˆåŠŸèƒ½ã€‚
    æ”¯æ´å¤šç¨® OCR æ¨¡å¼ï¼š
    - basic: PP-OCRv5 åŸºæœ¬æ–‡å­—è­˜åˆ¥
    - structure: PP-StructureV3 çµæ§‹åŒ–æ–‡ä»¶è§£æ
    - vl: PaddleOCR-VL è¦–è¦ºèªè¨€æ¨¡å‹
    
    ç›¸å®¹ PaddleOCR 3.x æ–°ç‰ˆ APIã€‚
    """
    
    def __init__(
        self,
        mode: str = "basic",
        use_orientation_classify: bool = False,
        use_doc_unwarping: bool = False,
        use_textline_orientation: bool = False,
        device: str = "gpu"
    ):
        """
        åˆå§‹åŒ– PaddleOCR å·¥å…·
        
        Args:
            mode: OCR æ¨¡å¼ ('basic', 'structure', 'vl')
            use_orientation_classify: æ˜¯å¦å•Ÿç”¨æ–‡ä»¶æ–¹å‘è‡ªå‹•æ ¡æ­£
            use_doc_unwarping: æ˜¯å¦å•Ÿç”¨æ–‡ä»¶å½æ›²æ ¡æ­£
            use_textline_orientation: æ˜¯å¦å•Ÿç”¨æ–‡å­—è¡Œæ–¹å‘åµæ¸¬
            device: é‹ç®—è¨­å‚™ ('gpu' æˆ– 'cpu')
        """
        self.mode = mode
        self.use_orientation_classify = use_orientation_classify
        self.use_doc_unwarping = use_doc_unwarping
        self.device = device
        
        # åˆå§‹åŒ–å°æ‡‰çš„ OCR å¼•æ“
        print(f"æ­£åœ¨åˆå§‹åŒ– PaddleOCR 3.x (æ¨¡å¼: {mode})...")
        
        try:
            if mode == "structure":
                if not HAS_STRUCTURE:
                    raise ImportError("PPStructureV3 æ¨¡çµ„ä¸å¯ç”¨ï¼Œè«‹ç¢ºèª paddleocr ç‰ˆæœ¬")
                self.ocr = PPStructureV3(
                    use_doc_orientation_classify=use_orientation_classify,
                    use_doc_unwarping=use_doc_unwarping,
                    use_textline_orientation=use_textline_orientation,
                    device=device
                )
                print("âœ“ PP-StructureV3 åˆå§‹åŒ–å®Œæˆï¼ˆçµæ§‹åŒ–æ–‡ä»¶è§£ææ¨¡å¼ï¼‰")
                
            elif mode == "vl":
                if not HAS_VL:
                    raise ImportError("PaddleOCRVL æ¨¡çµ„ä¸å¯ç”¨ï¼Œè«‹ç¢ºèª paddleocr ç‰ˆæœ¬")
                self.ocr = PaddleOCRVL(
                    use_doc_orientation_classify=use_orientation_classify,
                    use_doc_unwarping=use_doc_unwarping
                )
                print("âœ“ PaddleOCR-VL åˆå§‹åŒ–å®Œæˆï¼ˆè¦–è¦ºèªè¨€æ¨¡å‹æ¨¡å¼ï¼‰")
                
            elif mode == "formula":
                if not HAS_FORMULA:
                    raise ImportError("FormulaRecPipeline æ¨¡çµ„ä¸å¯ç”¨ï¼Œè«‹ç¢ºèª paddleocr ç‰ˆæœ¬")
                self.ocr = FormulaRecPipeline(
                    use_doc_orientation_classify=use_orientation_classify,
                    use_doc_unwarping=use_doc_unwarping,
                    device=device
                )
                print("âœ“ PP-FormulaNet åˆå§‹åŒ–å®Œæˆï¼ˆå…¬å¼è­˜åˆ¥æ¨¡å¼ï¼‰")
                
            elif mode == "hybrid":
                # æ··åˆæ¨¡å¼ï¼šåªä½¿ç”¨ PP-StructureV3ï¼ˆå…§å« OCRï¼‰
                if not HAS_STRUCTURE:
                    raise ImportError("PPStructureV3 æ¨¡çµ„ä¸å¯ç”¨ï¼Œè«‹ç¢ºèª paddleocr ç‰ˆæœ¬")
                
                print("  è¼‰å…¥ PP-StructureV3 å¼•æ“...")
                self.structure_engine = PPStructureV3(
                    use_doc_orientation_classify=use_orientation_classify,
                    use_doc_unwarping=use_doc_unwarping,
                    use_textline_orientation=use_textline_orientation,
                    device=device
                )
                
                # è¨­å®š self.ocr ç‚º structure_engine ä»¥ä¾¿å…¶ä»–æ–¹æ³•ä½¿ç”¨
                self.ocr = self.structure_engine
                print("âœ“ Hybrid æ¨¡å¼åˆå§‹åŒ–å®Œæˆï¼ˆPP-StructureV3 ç‰ˆé¢åˆ†æ + OCRï¼‰")
                
            else:  # basic æ¨¡å¼
                self.ocr = PaddleOCR(
                    use_doc_orientation_classify=use_orientation_classify,
                    use_doc_unwarping=use_doc_unwarping,
                    use_textline_orientation=use_textline_orientation
                )
                print("âœ“ PP-OCRv5 åˆå§‹åŒ–å®Œæˆï¼ˆåŸºæœ¬æ–‡å­—è­˜åˆ¥æ¨¡å¼ï¼‰")
                
        except Exception as e:
            print(f"åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    def _parse_predict_result(self, predict_result) -> List[OCRResult]:
        """
        è§£æ PaddleOCR 3.x predict() æ–¹æ³•çš„å›å‚³çµæœ
        
        Args:
            predict_result: predict() æ–¹æ³•å›å‚³çš„çµæœç‰©ä»¶
            
        Returns:
            List[OCRResult]: OCR è¾¨è­˜çµæœåˆ—è¡¨
        """
        results = []
        
        try:
            # PaddleOCR 3.x å›å‚³çµæœæ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ ä»£è¡¨ä¸€å€‹è¼¸å…¥
            for res in predict_result:
                # å–å¾— OCR çµæœ
                # æ–°ç‰ˆ API çš„çµæœçµæ§‹ï¼šres['rec_texts'], res['rec_scores'], res['dt_polys']
                if hasattr(res, 'rec_texts'):
                    texts = res.rec_texts if hasattr(res, 'rec_texts') else []
                    scores = res.rec_scores if hasattr(res, 'rec_scores') else []
                    polys = res.dt_polys if hasattr(res, 'dt_polys') else []
                    
                    for i, (text, score, poly) in enumerate(zip(texts, scores, polys)):
                        # å°‡ polygon è½‰æ›ç‚º bbox æ ¼å¼
                        bbox = poly.tolist() if hasattr(poly, 'tolist') else list(poly)
                        results.append(OCRResult(
                            text=str(text),
                            confidence=float(score),
                            bbox=bbox
                        ))
                elif hasattr(res, '__getitem__'):
                    # å˜—è©¦é€éå­—å…¸æ–¹å¼å­˜å–
                    texts = res.get('rec_texts', []) if isinstance(res, dict) else []
                    scores = res.get('rec_scores', []) if isinstance(res, dict) else []
                    polys = res.get('dt_polys', []) if isinstance(res, dict) else []
                    
                    for text, score, poly in zip(texts, scores, polys):
                        bbox = poly.tolist() if hasattr(poly, 'tolist') else list(poly)
                        results.append(OCRResult(
                            text=str(text),
                            confidence=float(score),
                            bbox=bbox
                        ))
        except Exception as e:
            print(f"è§£æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        return results
    
    def process_image(self, image_path: str) -> List[OCRResult]:
        """
        è™•ç†å–®å¼µåœ–ç‰‡é€²è¡Œ OCR
        
        Args:
            image_path: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
            
        Returns:
            List[OCRResult]: OCR è¾¨è­˜çµæœåˆ—è¡¨
        """
        results = []
        
        try:
            # PaddleOCR 3.x ä½¿ç”¨ predict() æ–¹æ³•
            predict_result = self.ocr.predict(input=image_path)
            results = self._parse_predict_result(predict_result)
            
            if not results:
                print(f"è­¦å‘Šï¼šæœªåœ¨åœ–ç‰‡ä¸­åµæ¸¬åˆ°æ–‡å­—: {image_path}")
            
            return results
            
        except Exception as e:
            print(f"éŒ¯èª¤ï¼šè™•ç†åœ–ç‰‡å¤±æ•— ({image_path}): {e}")
            return results
    
    def process_image_array(self, image_array: np.ndarray) -> List[OCRResult]:
        """
        è™•ç† numpy é™£åˆ—åœ–ç‰‡é€²è¡Œ OCR
        
        Args:
            image_array: numpy é™£åˆ—æ ¼å¼çš„åœ–ç‰‡
            
        Returns:
            List[OCRResult]: OCR è¾¨è­˜çµæœåˆ—è¡¨
        """
        results = []
        tmp_path = None
        
        try:
            # å°‡ numpy é™£åˆ—è½‰ç‚ºè‡¨æ™‚åœ–ç‰‡æª”æ¡ˆï¼Œå› ç‚º PaddleOCR 3.x predict() æ¥å—è·¯å¾‘
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                tmp_path = tmp_file.name
                Image.fromarray(image_array).save(tmp_path)
            
            try:
                predict_result = self.ocr.predict(input=tmp_path)
                results = self._parse_predict_result(predict_result)
            finally:
                # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                if tmp_path and os.path.exists(tmp_path):
                    try:
                        os.remove(tmp_path)
                    except:
                        pass
            
            # å¼·åˆ¶æ¸…ç†è¨˜æ†¶é«”
            del image_array
            gc.collect()
            
            return results
            
        except Exception as e:
            logging.error(f"è™•ç†åœ–ç‰‡é™£åˆ—å¤±æ•—: {e}")
            logging.error(traceback.format_exc())
            print(f"éŒ¯èª¤ï¼šè™•ç†åœ–ç‰‡é™£åˆ—å¤±æ•—: {e}")
            # ç¢ºä¿è‡¨æ™‚æª”æ¡ˆè¢«æ¸…ç†
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.remove(tmp_path)
                except:
                    pass
            return results
    
    def process_structured(
        self,
        input_path: str,
        markdown_output: Optional[str] = None,
        json_output: Optional[str] = None,
        excel_output: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ PP-StructureV3 æˆ– PaddleOCR-VL è™•ç†æ–‡ä»¶
        
        é©ç”¨æ–¼ structure å’Œ vl æ¨¡å¼ï¼Œç›´æ¥è¼¸å‡º Markdown/JSON/Excel æ ¼å¼
        
        Args:
            input_path: è¼¸å…¥æª”æ¡ˆè·¯å¾‘ï¼ˆPDF æˆ–åœ–ç‰‡ï¼‰
            markdown_output: Markdown è¼¸å‡ºç›®éŒ„ï¼ˆå¯é¸ï¼‰
            json_output: JSON è¼¸å‡ºç›®éŒ„ï¼ˆå¯é¸ï¼‰
            excel_output: Excel è¼¸å‡ºè·¯å¾‘ï¼ˆå¯é¸ï¼Œåƒ…è¡¨æ ¼ï¼‰
            
        Returns:
            Dict[str, Any]: è™•ç†çµæœæ‘˜è¦
        """
        if self.mode not in ["structure", "vl"]:
            raise ValueError(f"process_structured åƒ…é©ç”¨æ–¼ structure æˆ– vl æ¨¡å¼ï¼Œç•¶å‰æ¨¡å¼: {self.mode}")
        
        result_summary = {
            "input": input_path,
            "mode": self.mode,
            "pages_processed": 0,
            "markdown_files": [],
            "json_files": [],
            "excel_files": []
        }
        
        try:
            print(f"æ­£åœ¨è™•ç†: {input_path}")
            
            # ä½¿ç”¨ predict() æ–¹æ³•è™•ç†
            output = self.ocr.predict(input=input_path)
            
            # å–å¾—è…³æœ¬æ‰€åœ¨ç›®éŒ„ä½œç‚ºé è¨­è¼¸å‡ºç›®éŒ„
            script_dir = Path(__file__).parent.resolve()
            
            # è™•ç†è¼¸å‡ºè·¯å¾‘
            if markdown_output:
                md_path = Path(markdown_output)
                if not md_path.is_absolute():
                    md_path = script_dir / md_path
                md_output_dir = md_path.parent
                md_output_dir.mkdir(parents=True, exist_ok=True)
            
            if json_output:
                json_path = Path(json_output)
                if not json_path.is_absolute():
                    json_path = script_dir / json_path
                json_output_dir = json_path.parent
                json_output_dir.mkdir(parents=True, exist_ok=True)
            
            # è™•ç†æ¯å€‹çµæœ
            page_count = 0
            all_markdown_content = []
            
            for res in output:
                page_count += 1
                
                # ä½¿ç”¨å…§å»ºçš„å„²å­˜æ–¹æ³•
                if markdown_output:
                    # å»ºç«‹è‡¨æ™‚ç›®éŒ„ä¾†æ”¶é›† markdown
                    temp_dir = tempfile.mkdtemp()
                    try:
                        res.save_to_markdown(save_path=temp_dir)
                        # æ”¶é›†ç”Ÿæˆçš„ markdown å…§å®¹
                        for md_file in Path(temp_dir).glob("*.md"):
                            with open(md_file, 'r', encoding='utf-8') as f:
                                all_markdown_content.append(f"<!-- Page {page_count} -->\n" + f.read())
                    finally:
                        shutil.rmtree(temp_dir, ignore_errors=True)
                
                if json_output:
                    temp_dir = tempfile.mkdtemp()
                    try:
                        res.save_to_json(save_path=temp_dir)
                        # è¤‡è£½ç”Ÿæˆçš„ JSON åˆ°ç›®æ¨™ä½ç½®
                        for json_file in Path(temp_dir).glob("*.json"):
                            target_json = json_path.parent / f"{json_path.stem}_page{page_count}.json"
                            shutil.copy(json_file, target_json)
                            result_summary["json_files"].append(str(target_json))
                    finally:
                        shutil.rmtree(temp_dir, ignore_errors=True)
                
                # è¼¸å‡º Excelï¼ˆè¡¨æ ¼ï¼‰
                if excel_output:
                    if not HAS_OPENPYXL:
                        print("è­¦å‘Šï¼šéœ€è¦å®‰è£ openpyxl: pip install openpyxl")
                    else:
                        temp_dir = tempfile.mkdtemp()
                        try:
                            # å˜—è©¦å‘¼å« save_to_xlsxï¼ˆå¦‚æœçµæœç‰©ä»¶æ”¯æ´ï¼‰
                            if hasattr(res, 'save_to_xlsx'):
                                res.save_to_xlsx(save_path=temp_dir)
                                # è¤‡è£½ç”Ÿæˆçš„ Excel åˆ°ç›®æ¨™ä½ç½®
                                excel_path = Path(excel_output)
                                for xlsx_file in Path(temp_dir).glob("*.xlsx"):
                                    if excel_path.suffix == '.xlsx':
                                        target_xlsx = excel_path.parent / f"{excel_path.stem}_page{page_count}.xlsx"
                                    else:
                                        target_xlsx = Path(excel_output) / f"{Path(input_path).stem}_page{page_count}.xlsx"
                                    shutil.copy(xlsx_file, target_xlsx)
                                    result_summary["excel_files"].append(str(target_xlsx))
                        except Exception as excel_err:
                            logging.warning(f"Excel è¼¸å‡ºå¤±æ•— (é  {page_count}): {excel_err}")
                        finally:
                            shutil.rmtree(temp_dir, ignore_errors=True)
            
            # åˆä½µæ‰€æœ‰ markdown å…§å®¹åˆ°å–®ä¸€æª”æ¡ˆ
            if markdown_output and all_markdown_content:
                with open(md_path, 'w', encoding='utf-8') as f:
                    f.write("\n\n---\n\n".join(all_markdown_content))
                result_summary["markdown_files"].append(str(md_path))
                print(f"âœ“ Markdown å·²å„²å­˜ï¼š{md_path}")
            
            # Excel è¼¸å‡ºå®Œæˆè¨Šæ¯
            if result_summary.get("excel_files"):
                print(f"âœ“ Excel å·²å„²å­˜ï¼š{len(result_summary['excel_files'])} å€‹æª”æ¡ˆ")
            
            result_summary["pages_processed"] = page_count
            print(f"âœ“ è™•ç†å®Œæˆï¼š{page_count} é ")
            
            return result_summary
            
        except Exception as e:
            print(f"éŒ¯èª¤ï¼šè™•ç†å¤±æ•— ({input_path}): {e}")
            result_summary["error"] = str(e)
            return result_summary
    
    def process_pdf(
        self,
        pdf_path: str,
        output_path: Optional[str] = None,
        searchable: bool = False,
        dpi: int = 200,
        show_progress: bool = True
    ) -> Tuple[List[List[OCRResult]], Optional[str]]:
        """
        è™•ç† PDF æª”æ¡ˆé€²è¡Œ OCR
        
        Args:
            pdf_path: PDF æª”æ¡ˆè·¯å¾‘
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰
            searchable: æ˜¯å¦ç”Ÿæˆå¯æœå°‹ PDF
            dpi: PDF è½‰åœ–ç‰‡çš„è§£æåº¦
            
        Returns:
            Tuple[List[List[OCRResult]], Optional[str]]: 
                (æ¯é çš„ OCR çµæœåˆ—è¡¨, è¼¸å‡ºæª”æ¡ˆè·¯å¾‘)
        """
        all_results = []
        
        try:
            # é–‹å•Ÿ PDF
            logging.info(f"é–‹å•Ÿ PDF: {pdf_path}")
            pdf_doc = fitz.open(pdf_path)
            total_pages = len(pdf_doc)
            logging.info(f"PDF å…± {total_pages} é ")
            print(f"æ­£åœ¨è™•ç† PDF: {pdf_path} ({total_pages} é )")
            
            # æº–å‚™ PDF ç”Ÿæˆå™¨ï¼ˆå¦‚æœéœ€è¦ç”Ÿæˆå¯æœå°‹ PDFï¼‰
            pdf_generator = None
            if searchable:
                if not output_path:
                    base_name = Path(pdf_path).stem
                    output_path = str(Path(pdf_path).parent / f"{base_name}_searchable.pdf")
                logging.info(f"æº–å‚™ç”Ÿæˆå¯æœå°‹ PDF: {output_path}")
                pdf_generator = PDFGenerator(output_path)
            
            # è™•ç†æ¯ä¸€é ï¼ˆä½¿ç”¨é€²åº¦æ¢ï¼‰
            page_iterator = range(total_pages)
            if show_progress and HAS_TQDM:
                page_iterator = tqdm(
                    page_iterator,
                    desc="OCR è™•ç†ä¸­",
                    unit="é ",
                    ncols=80
                )
            
            for page_num in page_iterator:
                try:
                    logging.info(f"é–‹å§‹è™•ç†ç¬¬ {page_num + 1}/{total_pages} é ")
                    if not (show_progress and HAS_TQDM):
                        print(f"  è™•ç†ç¬¬ {page_num + 1}/{total_pages} é ...")
                    
                    page = pdf_doc[page_num]
                    
                    # å°‡é é¢è½‰æ›ç‚ºåœ–ç‰‡
                    logging.info(f"  è½‰æ›ç¬¬ {page_num + 1} é ç‚ºåœ–ç‰‡ (DPI: {dpi})")
                    zoom = dpi / 72.0
                    matrix = fitz.Matrix(zoom, zoom)
                    pixmap = page.get_pixmap(matrix=matrix)
                    logging.info(f"  åœ–ç‰‡å°ºå¯¸: {pixmap.width}x{pixmap.height}, è‰²å½©é€šé“: {pixmap.n}")
                    
                    # è½‰æ›ç‚º numpy é™£åˆ—ä»¥ä¾› PaddleOCR ä½¿ç”¨
                    img_array = np.frombuffer(pixmap.samples, dtype=np.uint8)
                    img_array = img_array.reshape(pixmap.height, pixmap.width, pixmap.n)
                    
                    # å¦‚æœæ˜¯ RGBAï¼Œè½‰æ›ç‚º RGB
                    if pixmap.n == 4:
                        img_array = img_array[:, :, :3]
                        logging.info(f"  å·²è½‰æ› RGBA ç‚º RGB")
                    
                    # åŸ·è¡Œ OCR
                    logging.info(f"  åŸ·è¡Œ OCR...")
                    page_results = self.process_image_array(img_array)
                    logging.info(f"  ç¬¬ {page_num + 1} é è¾¨è­˜åˆ° {len(page_results)} å€‹æ–‡å­—å€å¡Š")
                    all_results.append(page_results)
                    
                    # å°‡åº§æ¨™ç¸®æ”¾å›åŸå§‹ PDF å°ºå¯¸
                    scale_factor = 72.0 / dpi
                    for result in page_results:
                        result.bbox = [[p[0] * scale_factor, p[1] * scale_factor] for p in result.bbox]
                    
                    # å¦‚æœéœ€è¦ç”Ÿæˆå¯æœå°‹ PDF
                    if pdf_generator:
                        logging.info(f"  æ–°å¢ç¬¬ {page_num + 1} é åˆ°å¯æœå°‹ PDF")
                        # ä½¿ç”¨åŸå§‹é é¢å°ºå¯¸
                        original_pixmap = page.get_pixmap()
                        pdf_generator.add_page_from_pixmap(original_pixmap, page_results)
                        # æ¸…ç† pixmap
                        del original_pixmap
                    
                    # æ¸…ç†æœ¬é ä½¿ç”¨çš„è³‡æº
                    del pixmap
                    del img_array
                    del page_results
                    gc.collect()  # å¼·åˆ¶åƒåœ¾å›æ”¶ï¼Œé˜²æ­¢è¨˜æ†¶é«”æ´©æ¼
                    
                    logging.info(f"âœ“ ç¬¬ {page_num + 1}/{total_pages} é è™•ç†å®Œæˆ")
                    
                except Exception as page_error:
                    error_msg = f"è™•ç†ç¬¬ {page_num + 1} é æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(page_error)}"
                    logging.error(error_msg)
                    logging.error(traceback.format_exc())
                    print(f"  âš ï¸ {error_msg}")
                    # æ¸…ç†è³‡æºå¾Œç¹¼çºŒè™•ç†ä¸‹ä¸€é 
                    gc.collect()
                    all_results.append([])
            
            pdf_doc.close()
            logging.info("PDF æ–‡ä»¶å·²é—œé–‰")
            
            # å„²å­˜å¯æœå°‹ PDF
            if pdf_generator:
                logging.info("é–‹å§‹å„²å­˜å¯æœå°‹ PDF")
                pdf_generator.save()
            
            logging.info(f"âœ“ å®Œæˆè™•ç† {total_pages} é ï¼ŒæˆåŠŸ {len([r for r in all_results if r])} é ")
            return all_results, output_path
            
        except Exception as e:
            error_msg = f"è™•ç† PDF å¤±æ•— ({pdf_path}): {str(e)}"
            logging.error(error_msg)
            logging.error(traceback.format_exc())
            print(f"éŒ¯èª¤ï¼š{error_msg}")
            return all_results, None
    
    def process_directory(
        self,
        dir_path: str,
        output_path: Optional[str] = None,
        searchable: bool = False,
        recursive: bool = False
    ) -> Dict[str, List[OCRResult]]:
        """
        æ‰¹æ¬¡è™•ç†ç›®éŒ„ä¸­çš„æ‰€æœ‰åœ–ç‰‡å’Œ PDF
        
        Args:
            dir_path: ç›®éŒ„è·¯å¾‘
            output_path: è¼¸å‡ºè·¯å¾‘ï¼ˆå¯é¸ï¼‰
            searchable: æ˜¯å¦ç”Ÿæˆå¯æœå°‹ PDF
            recursive: æ˜¯å¦éè¿´è™•ç†å­ç›®éŒ„
            
        Returns:
            Dict[str, List[OCRResult]]: æª”æ¡ˆè·¯å¾‘åˆ° OCR çµæœçš„å°æ‡‰
        """
        all_results = {}
        dir_path = Path(dir_path)
        
        # æ”¶é›†æ‰€æœ‰æ”¯æ´çš„æª”æ¡ˆ
        files = []
        pattern = "**/*" if recursive else "*"
        
        for ext in SUPPORTED_IMAGE_FORMATS:
            files.extend(dir_path.glob(f"{pattern}{ext}"))
        files.extend(dir_path.glob(f"{pattern}{SUPPORTED_PDF_FORMAT}"))
        
        if not files:
            print(f"è­¦å‘Šï¼šåœ¨ç›®éŒ„ä¸­æœªæ‰¾åˆ°æ”¯æ´çš„æª”æ¡ˆ: {dir_path}")
            return all_results
        
        print(f"æ‰¾åˆ° {len(files)} å€‹æª”æ¡ˆå¾…è™•ç†")
        
        # å¦‚æœéœ€è¦åˆä½µç‚ºå¯æœå°‹ PDF
        if searchable:
            if not output_path:
                output_path = str(dir_path / f"{dir_path.name}_searchable.pdf")
            pdf_generator = PDFGenerator(output_path)
            
            for file_path in sorted(files):
                file_str = str(file_path)
                ext = file_path.suffix.lower()
                
                if ext == SUPPORTED_PDF_FORMAT:
                    # è™•ç† PDFï¼ˆå±•é–‹ç‚ºå¤šé ï¼‰
                    results, _ = self.process_pdf(file_str, searchable=False)
                    all_results[file_str] = []
                    for page_results in results:
                        all_results[file_str].extend(page_results)
                else:
                    # è™•ç†åœ–ç‰‡
                    results = self.process_image(file_str)
                    all_results[file_str] = results
                    if results:
                        pdf_generator.add_page(file_str, results)
            
            pdf_generator.save()
        else:
            # åƒ…åŸ·è¡Œ OCRï¼Œä¸ç”Ÿæˆ PDF
            for file_path in sorted(files):
                file_str = str(file_path)
                ext = file_path.suffix.lower()
                
                if ext == SUPPORTED_PDF_FORMAT:
                    results, _ = self.process_pdf(file_str, searchable=False)
                    all_results[file_str] = []
                    for page_results in results:
                        all_results[file_str].extend(page_results)
                else:
                    results = self.process_image(file_str)
                    all_results[file_str] = results
        
        return all_results
    
    def get_text(self, results: List[OCRResult], separator: str = "\n") -> str:
        """
        å¾ OCR çµæœä¸­æå–ç´”æ–‡å­—
        
        Args:
            results: OCR çµæœåˆ—è¡¨
            separator: è¡Œåˆ†éš”ç¬¦
            
        Returns:
            str: åˆä½µçš„ç´”æ–‡å­—
        """
        return separator.join(r.text for r in results if r.text.strip())
    
    def process_formula(
        self,
        input_path: str,
        latex_output: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ PP-FormulaNet è™•ç†æ•¸å­¸å…¬å¼è­˜åˆ¥
        
        Args:
            input_path: è¼¸å…¥æª”æ¡ˆè·¯å¾‘ï¼ˆåœ–ç‰‡æˆ– PDFï¼‰
            latex_output: LaTeX è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰
            
        Returns:
            Dict[str, Any]: è™•ç†çµæœæ‘˜è¦ï¼ŒåŒ…å«è­˜åˆ¥çš„å…¬å¼
        """
        if self.mode != "formula":
            raise ValueError(f"process_formula åƒ…é©ç”¨æ–¼ formula æ¨¡å¼ï¼Œç•¶å‰æ¨¡å¼: {self.mode}")
        
        result_summary = {
            "input": input_path,
            "formulas": [],
            "latex_file": None,
            "error": None
        }
        
        try:
            print(f"æ­£åœ¨è­˜åˆ¥å…¬å¼: {input_path}")
            logging.info(f"é–‹å§‹å…¬å¼è­˜åˆ¥: {input_path}")
            
            # åŸ·è¡Œå…¬å¼è­˜åˆ¥
            output = self.ocr.predict(input=input_path)
            
            all_latex = []
            for res in output:
                # å˜—è©¦å¤šç¨®æ–¹å¼æå– LaTeX
                latex = None
                
                # æ–¹å¼ 1ï¼šç›´æ¥å±¬æ€§
                if hasattr(res, 'rec_formula'):
                    latex = res.rec_formula
                # æ–¹å¼ 2ï¼šå­—å…¸å­˜å–
                elif isinstance(res, dict):
                    latex = res.get('rec_formula') or res.get('formula') or res.get('latex')
                # æ–¹å¼ 3ï¼šçµæœç‰©ä»¶çš„å…¶ä»–å±¬æ€§
                elif hasattr(res, '__dict__'):
                    for key in ['rec_formula', 'formula', 'latex', 'result']:
                        if hasattr(res, key):
                            latex = getattr(res, key)
                            if latex:
                                break
                
                if latex:
                    all_latex.append(str(latex))
                    logging.info(f"è­˜åˆ¥åˆ°å…¬å¼: {latex[:50]}...")
            
            result_summary["formulas"] = all_latex
            print(f"âœ“ è­˜åˆ¥åˆ° {len(all_latex)} å€‹å…¬å¼")
            
            # å„²å­˜ LaTeX æª”æ¡ˆ
            if latex_output and all_latex:
                with open(latex_output, 'w', encoding='utf-8') as f:
                    f.write("% å…¬å¼è­˜åˆ¥çµæœ\n")
                    f.write("% ç”± PaddleOCR å·¥å…·ç”Ÿæˆ\n")
                    f.write(f"% ä¾†æºæ–‡ä»¶: {input_path}\n\n")
                    
                    for i, latex in enumerate(all_latex, 1):
                        f.write(f"% å…¬å¼ {i}\n")
                        f.write(f"$$ {latex} $$\n\n")
                
                result_summary["latex_file"] = latex_output
                print(f"âœ“ LaTeX å·²å„²å­˜ï¼š{latex_output}")
                logging.info(f"LaTeX å·²å„²å­˜ï¼š{latex_output}")
            
            return result_summary
            
        except Exception as e:
            error_msg = f"å…¬å¼è­˜åˆ¥å¤±æ•—: {str(e)}"
            logging.error(error_msg)
            logging.error(traceback.format_exc())
            print(f"éŒ¯èª¤ï¼š{error_msg}")
            result_summary["error"] = str(e)
            return result_summary
    
    def process_hybrid(
        self,
        input_path: str,
        output_path: Optional[str] = None,
        markdown_output: Optional[str] = None,
        dpi: int = 150,
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        æ··åˆæ¨¡å¼ï¼šä½¿ç”¨ PP-StructureV3 ç‰ˆé¢åˆ†æ + PP-OCRv5 ç²¾ç¢ºåº§æ¨™
        
        ç”Ÿæˆé–±è®€é †åºæ­£ç¢ºçš„å¯æœå°‹ PDF å’Œ Markdown
        
        Args:
            input_path: è¼¸å…¥æª”æ¡ˆè·¯å¾‘ï¼ˆPDF æˆ–åœ–ç‰‡ï¼‰
            output_path: å¯æœå°‹ PDF è¼¸å‡ºè·¯å¾‘ï¼ˆå¯é¸ï¼‰
            markdown_output: Markdown è¼¸å‡ºè·¯å¾‘ï¼ˆå¯é¸ï¼‰
            dpi: PDF è½‰åœ–ç‰‡è§£æåº¦
            show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦æ¢
            
        Returns:
            Dict[str, Any]: è™•ç†çµæœæ‘˜è¦
        """
        if self.mode != "hybrid":
            raise ValueError(f"process_hybrid åƒ…é©ç”¨æ–¼ hybrid æ¨¡å¼ï¼Œç•¶å‰æ¨¡å¼: {self.mode}")
        
        result_summary = {
            "input": input_path,
            "mode": "hybrid",
            "pages_processed": 0,
            "searchable_pdf": None,
            "markdown_file": None,
            "text_content": [],
            "error": None
        }
        
        input_path_obj = Path(input_path)
        
        try:
            # è¨­å®šè¼¸å‡ºè·¯å¾‘
            if not output_path:
                output_path = str(input_path_obj.parent / f"{input_path_obj.stem}_hybrid.pdf")
            
            if not markdown_output:
                markdown_output = str(input_path_obj.parent / f"{input_path_obj.stem}_hybrid.md")
            
            print(f"æ­£åœ¨è™•ç†ï¼ˆæ··åˆæ¨¡å¼ï¼‰: {input_path}")
            logging.info(f"é–‹å§‹æ··åˆæ¨¡å¼è™•ç†: {input_path}")
            
            # åˆ¤æ–·è¼¸å…¥é¡å‹
            if input_path_obj.suffix.lower() == '.pdf':
                # è‡ªå‹•åµæ¸¬ PDF å“è³ªä¸¦èª¿æ•´ DPIï¼ˆå¦‚æœç”¨æˆ¶æœªæŒ‡å®šï¼‰
                if dpi == 150:  # ä½¿ç”¨é è¨­å€¼æ™‚æ‰è‡ªå‹•èª¿æ•´
                    quality = detect_pdf_quality(input_path)
                    if quality['recommended_dpi'] != 150:
                        print(f"ğŸ“„ {quality['reason']}")
                        print(f"   ä½¿ç”¨ DPI: {quality['recommended_dpi']}")
                        dpi = quality['recommended_dpi']
                
                return self._process_hybrid_pdf(
                    input_path, output_path, markdown_output, dpi, show_progress, result_summary
                )
            else:
                return self._process_hybrid_image(
                    input_path, output_path, markdown_output, result_summary
                )
                
        except Exception as e:
            error_msg = f"æ··åˆæ¨¡å¼è™•ç†å¤±æ•—: {str(e)}"
            logging.error(error_msg)
            logging.error(traceback.format_exc())
            print(f"éŒ¯èª¤ï¼š{error_msg}")
            result_summary["error"] = str(e)
            return result_summary
    
    def _process_hybrid_pdf(
        self,
        pdf_path: str,
        output_path: str,
        markdown_output: str,
        dpi: int,
        show_progress: bool,
        result_summary: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è™•ç† PDF çš„æ··åˆæ¨¡å¼"""
        
        pdf_doc = fitz.open(pdf_path)
        total_pages = len(pdf_doc)
        
        print(f"PDF å…± {total_pages} é ")
        logging.info(f"PDF å…± {total_pages} é ")
        
        # æº–å‚™ PDF ç”Ÿæˆå™¨
        pdf_generator = PDFGenerator(output_path)
        all_markdown = []
        all_text = []
        
        # è™•ç†æ¯ä¸€é 
        page_iterator = range(total_pages)
        if show_progress and HAS_TQDM:
            page_iterator = tqdm(page_iterator, desc="æ··åˆæ¨¡å¼è™•ç†ä¸­", unit="é ", ncols=80)
        
        for page_num in page_iterator:
            try:
                logging.info(f"è™•ç†ç¬¬ {page_num + 1}/{total_pages} é ")
                
                page = pdf_doc[page_num]
                
                # è½‰æ›ç‚ºåœ–ç‰‡
                zoom = dpi / 72.0
                matrix = fitz.Matrix(zoom, zoom)
                pixmap = page.get_pixmap(matrix=matrix)
                
                # è½‰æ›ç‚º numpy é™£åˆ—
                img_array = np.frombuffer(pixmap.samples, dtype=np.uint8)
                img_array = img_array.reshape(pixmap.height, pixmap.width, pixmap.n)
                if pixmap.n == 4:
                    img_array = img_array[:, :, :3]
                
                # æ­¥é©Ÿ 1ï¼šä½¿ç”¨ Structure å¼•æ“å–å¾—ç‰ˆé¢è³‡è¨Šå’Œ Markdown
                logging.info(f"  åŸ·è¡Œç‰ˆé¢åˆ†æ...")
                structure_output = self.structure_engine.predict(input=img_array)
                
                # ç›´æ¥å¾ PP-StructureV3 å–å¾—é«˜ç²¾åº¦ Markdown
                page_markdown = f"## ç¬¬ {page_num + 1} é \n\n"
                for res in structure_output:
                    # ä½¿ç”¨ save_to_markdown ä¿å­˜åˆ°è‡¨æ™‚ç›®éŒ„
                    temp_md_dir = tempfile.mkdtemp()
                    try:
                        if hasattr(res, 'save_to_markdown'):
                            res.save_to_markdown(save_path=temp_md_dir)
                            # è®€å–ç”Ÿæˆçš„ Markdown
                            for md_file in Path(temp_md_dir).glob("*.md"):
                                with open(md_file, 'r', encoding='utf-8') as f:
                                    page_markdown += f.read()
                                break
                    except Exception as md_err:
                        logging.warning(f"save_to_markdown å¤±æ•—: {md_err}")
                        # å›é€€ï¼šä½¿ç”¨ markdown å±¬æ€§
                        if hasattr(res, 'markdown') and isinstance(res.markdown, str):
                            page_markdown += res.markdown
                    finally:
                        shutil.rmtree(temp_md_dir, ignore_errors=True)
                
                # å¾ PP-StructureV3 è¼¸å‡ºæå–ç‰ˆé¢å€å¡Šè³‡è¨Š
                layout_blocks = []
                for res in structure_output:
                    try:
                        if hasattr(res, 'layout_parsing_result'):
                            # å˜—è©¦å¾ layout_parsing_result æå–
                            lp_result = res.layout_parsing_result
                            if hasattr(lp_result, 'blocks'):
                                layout_blocks.extend(lp_result.blocks)
                        if hasattr(res, 'blocks'):
                            layout_blocks.extend(res.blocks)
                        elif isinstance(res, dict):
                            blocks = res.get('blocks', []) or res.get('layout_blocks', [])
                            if blocks:
                                layout_blocks.extend(blocks)
                    except Exception as block_err:
                        logging.debug(f"æå–ç‰ˆé¢å€å¡Šå¤±æ•—: {block_err}")
                
                logging.info(f"  å–å¾— {len(layout_blocks)} å€‹ç‰ˆé¢å€å¡Š")
                
                # æ­¥é©Ÿ 2ï¼šå¾ PP-StructureV3 è¼¸å‡ºæå–æ–‡å­—åº§æ¨™ï¼Œä¸¦ä½¿ç”¨ Markdown éæ¿¾
                logging.info(f"  æå–æ–‡å­—åº§æ¨™ï¼ˆä½¿ç”¨ Markdown åŒ¹é…éæ¿¾ï¼‰...")
                sorted_results = self._extract_ocr_from_structure(structure_output, markdown_text=page_markdown)
                logging.info(f"  _extract_ocr_from_structure è¿”å› {len(sorted_results)} å€‹çµæœ")
                
                if sorted_results:
                    logging.info(f"  ç¬¬ä¸€å€‹çµæœ: text='{sorted_results[0].text[:20] if sorted_results[0].text else ''}...', x={sorted_results[0].x}, y={sorted_results[0].y}")
                else:
                    logging.warning(f"  æœªæå–åˆ°ä»»ä½• OCR çµæœ!")
                
                # æ­¥é©Ÿ 3ï¼šç”Ÿæˆå¯æœå°‹ PDF é é¢
                if sorted_results:
                    # å„²å­˜è‡¨æ™‚åœ–ç‰‡
                    tmp_path = tempfile.mktemp(suffix='.png')
                    try:
                        Image.fromarray(img_array).save(tmp_path)
                        pdf_generator.add_page(tmp_path, sorted_results)
                    finally:
                        if os.path.exists(tmp_path):
                            os.remove(tmp_path)
                
                # æ”¶é›† Markdown å’Œæ–‡å­—
                all_markdown.append(page_markdown)
                page_text = self.get_text(sorted_results)
                all_text.append(page_text)
                
                result_summary["pages_processed"] += 1
                
                # æ¸…ç†è¨˜æ†¶é«”
                del pixmap, img_array
                gc.collect()
                
            except Exception as page_error:
                logging.error(f"è™•ç†ç¬¬ {page_num + 1} é æ™‚ç™¼ç”ŸéŒ¯èª¤: {page_error}")
                logging.error(traceback.format_exc())
                continue
        
        pdf_doc.close()
        
        # å„²å­˜å¯æœå°‹ PDF
        if pdf_generator.save():
            result_summary["searchable_pdf"] = output_path
            print(f"âœ“ å¯æœå°‹ PDF å·²å„²å­˜ï¼š{output_path}")
        
        # å„²å­˜ Markdown
        if markdown_output and all_markdown:
            # æ‡‰ç”¨è‹±æ–‡ç©ºæ ¼ä¿®å¾©
            fixed_markdown = [fix_english_spacing(md) for md in all_markdown]
            with open(markdown_output, 'w', encoding='utf-8') as f:
                f.write("\n\n---\n\n".join(fixed_markdown))
            result_summary["markdown_file"] = markdown_output
            print(f"âœ“ Markdown å·²å„²å­˜ï¼š{markdown_output}")
        
        result_summary["text_content"] = all_text
        print(f"âœ“ æ··åˆæ¨¡å¼è™•ç†å®Œæˆï¼š{result_summary['pages_processed']} é ")
        
        return result_summary
    
    def _process_hybrid_image(
        self,
        image_path: str,
        output_path: str,
        markdown_output: str,
        result_summary: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è™•ç†åœ–ç‰‡çš„æ··åˆæ¨¡å¼"""
        
        logging.info(f"è™•ç†åœ–ç‰‡: {image_path}")
        
        # åŸ·è¡Œé›™å¼•æ“è™•ç†
        structure_output = self.structure_engine.predict(input=image_path)
        ocr_output = self.ocr_engine.predict(input=image_path)
        
        # åˆä½µçµæœ
        sorted_results, page_markdown = self._merge_hybrid_results(
            structure_output, ocr_output, 1
        )
        
        # ç”Ÿæˆå¯æœå°‹ PDF
        if sorted_results:
            pdf_generator = PDFGenerator(output_path)
            pdf_generator.add_page(image_path, sorted_results)
            if pdf_generator.save():
                result_summary["searchable_pdf"] = output_path
                print(f"âœ“ å¯æœå°‹ PDF å·²å„²å­˜ï¼š{output_path}")
        
        # å„²å­˜ Markdown
        if markdown_output and page_markdown:
            with open(markdown_output, 'w', encoding='utf-8') as f:
                f.write(page_markdown)
            result_summary["markdown_file"] = markdown_output
            print(f"âœ“ Markdown å·²å„²å­˜ï¼š{markdown_output}")
        
        result_summary["pages_processed"] = 1
        result_summary["text_content"] = [self.get_text(sorted_results)]
        
        return result_summary
    
    def _merge_hybrid_results(
        self,
        structure_output,
        ocr_output,
        page_num: int
    ) -> Tuple[List[OCRResult], str]:
        """
        åˆä½µç‰ˆé¢åˆ†æå’Œ OCR çµæœ
        
        Args:
            structure_output: PP-StructureV3 çš„è¼¸å‡º
            ocr_output: PP-OCRv5 çš„è¼¸å‡º
            page_num: é ç¢¼
            
        Returns:
            Tuple[List[OCRResult], str]: æ’åºå¾Œçš„ OCR çµæœå’Œ Markdown å…§å®¹
        """
        # è§£æ OCR çµæœå–å¾—ç²¾ç¢ºåº§æ¨™
        ocr_results = self._parse_predict_result(ocr_output)
        
        # å˜—è©¦å¾ structure è¼¸å‡ºå–å¾—ç‰ˆé¢è³‡è¨Š
        layout_blocks = []
        markdown_parts = []
        
        try:
            for res in structure_output:
                # å–å¾— Markdown å…§å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                md_content = None
                
                if hasattr(res, 'markdown'):
                    md_content = res.markdown
                elif isinstance(res, dict):
                    md_content = res.get('markdown', None)
                
                # ç¢ºä¿åªæ·»åŠ å­—ä¸²é¡å‹
                if md_content is not None:
                    if isinstance(md_content, str):
                        markdown_parts.append(md_content)
                    elif isinstance(md_content, dict):
                        # å¦‚æœæ˜¯ dictï¼Œå˜—è©¦æå–æ–‡å­—å…§å®¹
                        text = md_content.get('text', '') or md_content.get('content', '')
                        if text and isinstance(text, str):
                            markdown_parts.append(text)
                    elif isinstance(md_content, list):
                        # å¦‚æœæ˜¯ listï¼Œé€£æ¥æ‰€æœ‰å­—ä¸²å…ƒç´ 
                        for item in md_content:
                            if isinstance(item, str):
                                markdown_parts.append(item)
                            elif isinstance(item, dict):
                                text = item.get('text', '') or item.get('content', '')
                                if text and isinstance(text, str):
                                    markdown_parts.append(text)
                
                # å–å¾—ç‰ˆé¢å€å¡Šè³‡è¨Š
                if hasattr(res, 'layout_blocks'):
                    layout_blocks.extend(res.layout_blocks)
                elif hasattr(res, 'blocks'):
                    layout_blocks.extend(res.blocks)
                elif isinstance(res, dict):
                    blocks = res.get('layout_blocks', []) or res.get('blocks', [])
                    if blocks:
                        layout_blocks.extend(blocks)
                        
        except Exception as e:
            logging.warning(f"è§£æ structure è¼¸å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # å¦‚æœæœ‰ç‰ˆé¢è³‡è¨Šï¼Œæ ¹æ“šç‰ˆé¢é †åºæ’åº OCR çµæœ
        if layout_blocks:
            sorted_results = self._sort_ocr_by_layout(ocr_results, layout_blocks)
        else:
            # æ²’æœ‰ç‰ˆé¢è³‡è¨Šï¼Œä½¿ç”¨é è¨­çš„å¾ä¸Šåˆ°ä¸‹ã€å¾å·¦åˆ°å³æ’åº
            sorted_results = self._sort_ocr_by_position(ocr_results)
        
        # çµ„åˆ Markdown
        if markdown_parts:
            # éæ¿¾ç©ºå­—ä¸²
            valid_parts = [p for p in markdown_parts if p and isinstance(p, str)]
            if valid_parts:
                page_markdown = f"## ç¬¬ {page_num} é \n\n" + "\n\n".join(valid_parts)
            else:
                page_markdown = f"## ç¬¬ {page_num} é \n\n" + self.get_text(sorted_results, separator="\n\n")
        else:
            # ä½¿ç”¨æ’åºå¾Œçš„æ–‡å­—ç”Ÿæˆ Markdown
            page_markdown = f"## ç¬¬ {page_num} é \n\n" + self.get_text(sorted_results, separator="\n\n")
        
        return sorted_results, page_markdown
    
    def _extract_ocr_from_structure(self, structure_output, markdown_text: str = None) -> List[OCRResult]:
        """
        å¾ PP-StructureV3 è¼¸å‡ºæå–æ–‡å­—åº§æ¨™
        
        Args:
            structure_output: PP-StructureV3 çš„è¼¸å‡ºï¼ˆLayoutParsingResultV2 åˆ—è¡¨ï¼‰
            markdown_text: å¯é¸ï¼ŒMarkdown æ–‡å­—ç”¨æ–¼éæ¿¾ OCR çµæœ
            
        Returns:
            List[OCRResult]: OCR çµæœåˆ—è¡¨
        """
        ocr_results = []
        
        # å¦‚æœæä¾›äº† markdown_textï¼Œæå–å…¶ä¸­çš„æ–‡å­—ç”¨æ–¼åŒ¹é…
        markdown_texts_set = set()
        if markdown_text:
            # æ¸…ç† markdown èªæ³•ï¼Œæå–ç´”æ–‡å­—
            import re
            # ç§»é™¤ markdown æ¨™è¨˜
            clean_text = re.sub(r'#+ ', '', markdown_text)  # ç§»é™¤æ¨™é¡Œ
            clean_text = re.sub(r'\*\*|__', '', clean_text)  # ç§»é™¤ç²—é«”
            clean_text = re.sub(r'\*|_', '', clean_text)  # ç§»é™¤æ–œé«”
            clean_text = re.sub(r'!\[.*?\]\(.*?\)', '', clean_text)  # ç§»é™¤åœ–ç‰‡
            clean_text = re.sub(r'\[.*?\]\(.*?\)', '', clean_text)  # ç§»é™¤é€£çµ
            # åˆ†å‰²æˆè¡Œï¼Œéæ¿¾ç©ºè¡Œ
            for line in clean_text.split('\n'):
                line = line.strip()
                if line and len(line) > 1:  # å¿½ç•¥å–®å€‹å­—ç¬¦
                    markdown_texts_set.add(line)
            logging.info(f"  Markdown æ–‡å­—è¡Œæ•¸: {len(markdown_texts_set)}")
        
        try:
            
            for res in structure_output:
                # æ–¹å¼ 1ï¼šå¾ overall_ocr_res æå–ï¼ˆé€™æ˜¯ä¸»è¦çš„ OCR çµæœï¼‰
                if 'overall_ocr_res' in res:
                    overall_ocr = res['overall_ocr_res']
                    
                    if overall_ocr is not None:
                        logging.info(f"  å¾ overall_ocr_res æå–")
                        
                        # overall_ocr_res æ˜¯ dict-like çš„ OCRResult å°è±¡
                        try:
                            # ç²å–æ–‡å­—å’Œåˆ†æ•¸
                            texts = overall_ocr.get('rec_texts', [])
                            scores = overall_ocr.get('rec_scores', [])
                            
                            # å„ªå…ˆä½¿ç”¨ rec_boxesï¼ˆæ ¼å¼ï¼š[x1, y1, x2, y2]ï¼‰
                            rec_boxes = overall_ocr.get('rec_boxes')
                            dt_polys = overall_ocr.get('dt_polys', [])
                            
                            logging.info(f"  texts: {len(texts) if texts else 0}, rec_boxes: {len(rec_boxes) if rec_boxes is not None else 0}")
                            
                            if texts:
                                # æ–¹å¼ 1ï¼šä½¿ç”¨ rec_boxesï¼ˆæ›´ç°¡å–®ï¼‰
                                if rec_boxes is not None and len(rec_boxes) > 0:
                                    boxes_list = rec_boxes.tolist() if hasattr(rec_boxes, 'tolist') else rec_boxes
                                    
                                    for i, (box, text) in enumerate(zip(boxes_list, texts)):
                                        try:
                                            if text:
                                                # å¦‚æœæœ‰ markdown éæ¿¾ï¼Œæª¢æŸ¥æ–‡å­—æ˜¯å¦åŒ¹é…
                                                if markdown_texts_set:
                                                    # æª¢æŸ¥ OCR æ–‡å­—æ˜¯å¦åœ¨ä»»ä½• markdown è¡Œä¸­å‡ºç¾
                                                    text_matched = False
                                                    for md_line in markdown_texts_set:
                                                        if text in md_line or md_line in text:
                                                            text_matched = True
                                                            break
                                                    if not text_matched:
                                                        continue  # è·³éä¸åŒ¹é…çš„æ–‡å­—
                                                
                                                # box æ ¼å¼: [x1, y1, x2, y2] -> è½‰æ›ç‚º bbox æ ¼å¼ [[x1,y1], [x2,y1], [x2,y2], [x1,y2]]
                                                x1, y1, x2, y2 = float(box[0]), float(box[1]), float(box[2]), float(box[3])
                                                bbox = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]
                                                conf = float(scores[i]) if i < len(scores) else 0.9
                                                
                                                ocr_results.append(OCRResult(
                                                    text=str(text),
                                                    confidence=conf,
                                                    bbox=bbox
                                                ))
                                        except Exception as e:
                                            logging.debug(f"  è™•ç† box {i} å¤±æ•—: {e}")
                                            continue
                                    logging.info(f"  å¾ rec_boxes æå–äº† {len(ocr_results)} å€‹çµæœ")
                                
                                # æ–¹å¼ 2ï¼šä½¿ç”¨ dt_polys
                                elif dt_polys and len(dt_polys) > 0:
                                    for i, (poly, text) in enumerate(zip(dt_polys, texts)):
                                        try:
                                            if poly is not None and text:
                                                # å¦‚æœæœ‰ markdown éæ¿¾ï¼Œæª¢æŸ¥æ–‡å­—æ˜¯å¦åŒ¹é…
                                                if markdown_texts_set:
                                                    text_matched = False
                                                    for md_line in markdown_texts_set:
                                                        if text in md_line or md_line in text:
                                                            text_matched = True
                                                            break
                                                    if not text_matched:
                                                        continue
                                                
                                                poly_list = poly.tolist() if hasattr(poly, 'tolist') else poly
                                                # ç¢ºä¿æ˜¯ [[x,y], [x,y], ...] æ ¼å¼
                                                bbox = [[float(p[0]), float(p[1])] for p in poly_list]
                                                conf = float(scores[i]) if i < len(scores) else 0.9
                                                
                                                ocr_results.append(OCRResult(
                                                    text=str(text),
                                                    confidence=conf,
                                                    bbox=bbox
                                                ))
                                        except Exception as e:
                                            logging.debug(f"  è™•ç† poly {i} å¤±æ•—: {e}")
                                            continue
                                    logging.info(f"  å¾ dt_polys æå–äº† {len(ocr_results)} å€‹çµæœ")
                                    
                        except Exception as e:
                            logging.warning(f"  è¨ªå• overall_ocr_res å¤±æ•—: {e}")
                            logging.warning(traceback.format_exc())
                
                # æ–¹å¼ 2ï¼šå¾ parsing_res_list çš„ LayoutBlock æå–
                if not ocr_results and 'parsing_res_list' in res:
                    parsing_list = res['parsing_res_list']
                    if parsing_list:
                        logging.info(f"  å¾ parsing_res_list æå–ï¼Œå…± {len(parsing_list)} å€‹å€å¡Š")
                        
                        for block in parsing_list:
                            try:
                                # LayoutBlock æœ‰ bbox å’Œ content å±¬æ€§
                                bbox = getattr(block, 'bbox', None)
                                content = getattr(block, 'content', None)
                                
                                if bbox is not None and content:
                                    # bbox æ ¼å¼å¯èƒ½æ˜¯ [x1, y1, x2, y2]
                                    if len(bbox) >= 4:
                                        x1, y1, x2, y2 = float(bbox[0]), float(bbox[1]), float(bbox[2]), float(bbox[3])
                                        bbox_points = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]
                                        ocr_results.append(OCRResult(
                                            text=str(content),
                                            confidence=0.9,
                                            bbox=bbox_points
                                        ))
                            except Exception as e:
                                logging.debug(f"  è™•ç† block å¤±æ•—: {e}")
                                continue
                        
                        logging.info(f"  å¾ parsing_res_list æå–äº† {len(ocr_results)} å€‹çµæœ")
                            
        except Exception as e:
            logging.warning(f"å¾ structure è¼¸å‡ºæå– OCR çµæœå¤±æ•—: {e}")
            logging.warning(traceback.format_exc())
        
        logging.info(f"  ç¸½å…±æå– {len(ocr_results)} å€‹ OCR çµæœ")
        return ocr_results
    
    def _sort_ocr_by_layout(
        self,
        ocr_results: List[OCRResult],
        layout_blocks: List
    ) -> List[OCRResult]:
        """æ ¹æ“šç‰ˆé¢å€å¡Šé †åºæ’åº OCR çµæœ"""
        
        if not layout_blocks:
            return self._sort_ocr_by_position(ocr_results)
        
        # å»ºç«‹å€å¡Šåˆ° OCR çµæœçš„å°æ‡‰
        block_results = {i: [] for i in range(len(layout_blocks))}
        unassigned = []
        
        for ocr in ocr_results:
            assigned = False
            ocr_center = (ocr.x + ocr.width / 2, ocr.y + ocr.height / 2)
            
            for i, block in enumerate(layout_blocks):
                try:
                    # å–å¾—å€å¡Šé‚Šç•Œ
                    if hasattr(block, 'bbox'):
                        bbox = block.bbox
                    elif isinstance(block, dict) and 'bbox' in block:
                        bbox = block['bbox']
                    else:
                        continue
                    
                    # æª¢æŸ¥ OCR çµæœæ˜¯å¦åœ¨å€å¡Šå…§
                    if (bbox[0] <= ocr_center[0] <= bbox[2] and
                        bbox[1] <= ocr_center[1] <= bbox[3]):
                        block_results[i].append(ocr)
                        assigned = True
                        break
                except:
                    continue
            
            if not assigned:
                unassigned.append(ocr)
        
        # æŒ‰å€å¡Šé †åºçµ„åˆçµæœ
        sorted_results = []
        for i in range(len(layout_blocks)):
            # å€å¡Šå…§çš„çµæœæŒ‰ä½ç½®æ’åº
            block_ocrs = self._sort_ocr_by_position(block_results[i])
            sorted_results.extend(block_ocrs)
        
        # åŠ å…¥æœªåˆ†é…çš„çµæœ
        sorted_results.extend(self._sort_ocr_by_position(unassigned))
        
        return sorted_results
    
    def _sort_ocr_by_position(self, ocr_results: List[OCRResult]) -> List[OCRResult]:
        """æŒ‰ä½ç½®æ’åº OCR çµæœï¼ˆå¾ä¸Šåˆ°ä¸‹ã€å¾å·¦åˆ°å³ï¼‰"""
        
        if not ocr_results:
            return []
        
        # æŒ‰ Y åº§æ¨™åˆ†çµ„ï¼ˆåŒä¸€è¡Œï¼‰
        line_threshold = 10  # åƒç´ é–¾å€¼
        lines = []
        
        sorted_by_y = sorted(ocr_results, key=lambda r: r.y)
        
        current_line = [sorted_by_y[0]]
        current_y = sorted_by_y[0].y
        
        for ocr in sorted_by_y[1:]:
            if abs(ocr.y - current_y) <= line_threshold:
                current_line.append(ocr)
            else:
                lines.append(current_line)
                current_line = [ocr]
                current_y = ocr.y
        
        lines.append(current_line)
        
        # æ¯è¡ŒæŒ‰ X åº§æ¨™æ’åº
        sorted_results = []
        for line in lines:
            sorted_line = sorted(line, key=lambda r: r.x)
            sorted_results.extend(sorted_line)
        
        return sorted_results

    def process_translate(
        self,
        input_path: str,
        output_path: Optional[str] = None,
        source_lang: str = "auto",
        target_lang: str = "en",
        ollama_model: str = "qwen2.5:7b",
        ollama_url: str = "http://localhost:11434",
        no_mono: bool = False,
        no_dual: bool = False,
        dual_mode: str = "alternating",
        dual_translate_first: bool = False,
        font_path: Optional[str] = None,
        dpi: int = 150,
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        ç¿»è­¯ PDF ä¸¦ç”Ÿæˆå¤šç¨®è¼¸å‡º
        
        è¼¸å‡ºæª”æ¡ˆï¼š
        - *_hybrid.pdfï¼šå¯æœå°‹ PDF
        - *_hybrid.mdï¼šMarkdown è¼¸å‡º
        - *_translated_{lang}.pdfï¼šç´”ç¿»è­¯ PDFï¼ˆé™¤é --no-monoï¼‰
        - *_bilingual_{lang}.pdfï¼šé›™èªå°ç…§ PDFï¼ˆé™¤é --no-dualï¼‰
        
        Args:
            input_path: è¼¸å…¥ PDF è·¯å¾‘
            output_path: å¯æœå°‹ PDF è¼¸å‡ºè·¯å¾‘ï¼ˆå¯é¸ï¼‰
            source_lang: ä¾†æºèªè¨€ï¼ˆauto=è‡ªå‹•åµæ¸¬ï¼‰
            target_lang: ç›®æ¨™èªè¨€
            ollama_model: Ollama æ¨¡å‹åç¨±
            ollama_url: Ollama API åœ°å€
            no_mono: ä¸è¼¸å‡ºç´”ç¿»è­¯ PDF
            no_dual: ä¸è¼¸å‡ºé›™èªå°ç…§ PDF
            dual_mode: é›™èªæ¨¡å¼ï¼ˆalternating æˆ– side-by-sideï¼‰
            dual_translate_first: é›™èªæ¨¡å¼ä¸­è­¯æ–‡åœ¨å‰
            font_path: è‡ªè¨‚å­—é«”è·¯å¾‘
            dpi: PDF è½‰åœ–ç‰‡è§£æåº¦
            show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦æ¢
            
        Returns:
            Dict[str, Any]: è™•ç†çµæœæ‘˜è¦
        """
        if not HAS_TRANSLATOR:
            raise ImportError("ç¿»è­¯æ¨¡çµ„ä¸å¯ç”¨ï¼Œè«‹ç¢ºèª pdf_translator.py å­˜åœ¨ä¸”ä¾è³´å·²å®‰è£")
        
        if self.mode != "hybrid":
            raise ValueError(f"process_translate éœ€è¦ hybrid æ¨¡å¼ï¼Œç•¶å‰æ¨¡å¼: {self.mode}")
        
        result_summary = {
            "input": input_path,
            "mode": "translate",
            "source_lang": source_lang,
            "target_lang": target_lang,
            "pages_processed": 0,
            "searchable_pdf": None,
            "markdown_file": None,
            "translated_pdf": None,
            "bilingual_pdf": None,
            "error": None
        }
        
        input_path_obj = Path(input_path)
        
        try:
            # è¨­å®šè¼¸å‡ºè·¯å¾‘
            base_path = input_path_obj.parent / input_path_obj.stem
            
            if not output_path:
                output_path = str(base_path) + "_hybrid.pdf"
            
            markdown_output = str(base_path) + "_hybrid.md"
            translated_output = str(base_path) + f"_translated_{target_lang}.pdf" if not no_mono else None
            bilingual_output = str(base_path) + f"_bilingual_{target_lang}.pdf" if not no_dual else None
            
            print(f"\nğŸŒ æ­£åœ¨è™•ç†ï¼ˆç¿»è­¯æ¨¡å¼ï¼‰: {input_path}")
            print(f"   ä¾†æºèªè¨€: {source_lang}")
            print(f"   ç›®æ¨™èªè¨€: {target_lang}")
            print(f"   Ollama æ¨¡å‹: {ollama_model}")
            logging.info(f"é–‹å§‹ç¿»è­¯æ¨¡å¼è™•ç†: {input_path}")
            
            # åˆå§‹åŒ–ç¿»è­¯å™¨
            translator = OllamaTranslator(model=ollama_model, base_url=ollama_url)
            inpainter = TextInpainter()
            renderer = TextRenderer(font_path=font_path)
            
            # åˆå§‹åŒ– PDF ç”Ÿæˆå™¨
            pdf_generator = PDFGenerator(output_path)
            mono_generator = MonolingualPDFGenerator() if translated_output else None
            bilingual_generator = BilingualPDFGenerator(
                mode=dual_mode,
                translate_first=dual_translate_first
            ) if bilingual_output else None
            
            # è™•ç† PDF
            pdf_doc = fitz.open(input_path)
            total_pages = len(pdf_doc)
            all_markdown = []
            
            print(f"PDF å…± {total_pages} é ")
            logging.info(f"PDF å…± {total_pages} é ")
            
            # é€²åº¦æ¢
            page_iter = range(total_pages)
            if show_progress and HAS_TQDM:
                page_iter = tqdm(page_iter, desc="ç¿»è­¯é é¢", unit="é ", ncols=80)
            
            for page_num in page_iter:
                try:
                    page = pdf_doc[page_num]
                    
                    # è½‰æ›ç‚ºåœ–ç‰‡
                    zoom = dpi / 72.0
                    matrix = fitz.Matrix(zoom, zoom)
                    pixmap = page.get_pixmap(matrix=matrix)
                    
                    img_array = np.frombuffer(pixmap.samples, dtype=np.uint8)
                    img_array = img_array.reshape(pixmap.height, pixmap.width, pixmap.n).copy()
                    if pixmap.n == 4:
                        img_array = img_array[:, :, :3].copy()
                    
                    original_image = img_array.copy()
                    
                    # ä½¿ç”¨ PP-Structure é€²è¡Œç‰ˆé¢åˆ†æå’Œ OCR
                    logging.info(f"  ç¬¬ {page_num + 1} é ï¼šç‰ˆé¢åˆ†æä¸­...")
                    structure_output = self.structure_engine.predict(input=img_array.copy())
                    
                    # æå– Markdown
                    page_markdown = f"## ç¬¬ {page_num + 1} é \n\n"
                    for res in structure_output:
                        temp_md_dir = tempfile.mkdtemp()
                        try:
                            if hasattr(res, 'save_to_markdown'):
                                res.save_to_markdown(save_path=temp_md_dir)
                                for md_file in Path(temp_md_dir).glob("*.md"):
                                    with open(md_file, 'r', encoding='utf-8') as f:
                                        page_markdown += f.read()
                                    break
                        except Exception as md_err:
                            logging.warning(f"save_to_markdown å¤±æ•—: {md_err}")
                            if hasattr(res, 'markdown') and isinstance(res.markdown, str):
                                page_markdown += res.markdown
                        finally:
                            shutil.rmtree(temp_md_dir, ignore_errors=True)
                    
                    all_markdown.append(page_markdown)
                    
                    # æå– OCR çµæœ
                    ocr_results = self._extract_ocr_from_structure(structure_output, markdown_text=page_markdown)
                    
                    # æ·»åŠ åˆ°å¯æœå°‹ PDF
                    if ocr_results:
                        tmp_path = tempfile.mktemp(suffix='.png')
                        try:
                            Image.fromarray(img_array).save(tmp_path)
                            pdf_generator.add_page(tmp_path, ocr_results)
                        finally:
                            if os.path.exists(tmp_path):
                                os.remove(tmp_path)
                    
                    # ç¿»è­¯æµç¨‹
                    if mono_generator or bilingual_generator:
                        logging.info(f"  ç¬¬ {page_num + 1} é ï¼šç¿»è­¯ä¸­...")
                        
                        # æ”¶é›†éœ€è¦ç¿»è­¯çš„æ–‡å­—
                        texts_to_translate = []
                        bboxes = []
                        
                        for result in ocr_results:
                            if result.text and result.text.strip():
                                texts_to_translate.append(result.text)
                                bboxes.append(result.bbox)
                        
                        # ç¿»è­¯æ–‡å­—
                        if texts_to_translate:
                            print(f"  ç¿»è­¯ {len(texts_to_translate)} å€‹æ–‡å­—å€å¡Š...")
                            translated_texts = translator.translate_batch(
                                texts_to_translate, source_lang, target_lang, show_progress=False
                            )
                            
                            # å»ºç«‹ç¿»è­¯å€å¡Š
                            translated_blocks = []
                            for orig, trans, bbox in zip(texts_to_translate, translated_texts, bboxes):
                                translated_blocks.append(TranslatedBlock(
                                    original_text=orig,
                                    translated_text=trans,
                                    bbox=bbox
                                ))
                            
                            # è™•ç†åœ–ç‰‡ï¼šæ“¦é™¤åŸæ–‡ä¸¦ç¹ªè£½è­¯æ–‡
                            translated_image = img_array.copy()
                            
                            if inpainter and translated_blocks:
                                all_bboxes = [block.bbox for block in translated_blocks]
                                translated_image = inpainter.erase_multiple_regions(
                                    translated_image, all_bboxes, fill_color=(255, 255, 255)
                                )
                            
                            # ç¹ªè£½è­¯æ–‡
                            translated_image = renderer.render_multiple_texts(
                                translated_image, translated_blocks
                            )
                            
                            # æ·»åŠ åˆ°ç´”ç¿»è­¯ PDF
                            if mono_generator:
                                mono_generator.add_page(translated_image)
                            
                            # æ·»åŠ åˆ°é›™èªå°ç…§ PDF
                            if bilingual_generator:
                                bilingual_generator.add_bilingual_page(
                                    original_image, translated_image
                                )
                        else:
                            # æ²’æœ‰æ–‡å­—éœ€è¦ç¿»è­¯ï¼Œä¿ç•™åŸåœ–
                            if mono_generator:
                                mono_generator.add_page(original_image)
                            if bilingual_generator:
                                bilingual_generator.add_bilingual_page(
                                    original_image, original_image
                                )
                    
                    result_summary["pages_processed"] += 1
                    
                    # æ¸…ç†è¨˜æ†¶é«”
                    del pixmap, img_array
                    gc.collect()
                    
                except Exception as page_error:
                    logging.error(f"è™•ç†ç¬¬ {page_num + 1} é æ™‚ç™¼ç”ŸéŒ¯èª¤: {page_error}")
                    logging.error(traceback.format_exc())
                    continue
            
            pdf_doc.close()
            
            # å„²å­˜å¯æœå°‹ PDF
            if pdf_generator.save():
                result_summary["searchable_pdf"] = output_path
            
            # å„²å­˜ Markdown
            if all_markdown:
                with open(markdown_output, 'w', encoding='utf-8') as f:
                    f.write("\n\n---\n\n".join(all_markdown))
                result_summary["markdown_file"] = markdown_output
                print(f"âœ“ Markdown å·²å„²å­˜ï¼š{markdown_output}")
            
            # å„²å­˜ç¿»è­¯ PDF
            if mono_generator and mono_generator.save(translated_output):
                result_summary["translated_pdf"] = translated_output
                mono_generator.close()
            
            # å„²å­˜é›™èªå°ç…§ PDF
            if bilingual_generator and bilingual_generator.save(bilingual_output):
                result_summary["bilingual_pdf"] = bilingual_output
                bilingual_generator.close()
            
            print(f"âœ“ ç¿»è­¯è™•ç†å®Œæˆï¼š{result_summary['pages_processed']} é ")
            
            return result_summary
            
        except Exception as e:
            error_msg = f"ç¿»è­¯è™•ç†å¤±æ•—: {str(e)}"
            logging.error(error_msg)
            logging.error(traceback.format_exc())
            print(f"éŒ¯èª¤ï¼š{error_msg}")
            result_summary["error"] = str(e)
            return result_summary


def main():
    """å‘½ä»¤åˆ—å…¥å£é»"""
    parser = argparse.ArgumentParser(
        description="PaddleOCR å·¥å…· - å¤šåŠŸèƒ½æ–‡ä»¶è¾¨è­˜èˆ‡è™•ç†å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
    # åŸºæœ¬ OCRï¼ˆè¼¸å‡ºæ–‡å­—åˆ°çµ‚ç«¯æ©Ÿï¼‰
    python paddle_ocr_tool.py input.pdf
    
    # ç”Ÿæˆå¯æœå°‹ PDF
    python paddle_ocr_tool.py input.pdf --searchable
    
    # PP-StructureV3 æ¨¡å¼ï¼ˆè¼¸å‡º Markdown å’Œ Excelï¼‰
    python paddle_ocr_tool.py input.pdf --mode structure --markdown-output result.md --excel-output tables.xlsx
    
    # PaddleOCR-VL æ¨¡å¼ï¼ˆè¼¸å‡º JSONï¼‰
    python paddle_ocr_tool.py input.pdf --mode vl --json-output result.json
    
    # å…¬å¼è­˜åˆ¥æ¨¡å¼ï¼ˆè¼¸å‡º LaTeXï¼‰
    python paddle_ocr_tool.py math_image.png --mode formula --latex-output formulas.tex
    
    # å•Ÿç”¨æ–‡ä»¶æ–¹å‘æ ¡æ­£
    python paddle_ocr_tool.py input.pdf --orientation-classify --text-output result.txt
    
    # æ‰¹æ¬¡è™•ç†ç›®éŒ„
    python paddle_ocr_tool.py ./images/ --searchable
    
    # å„²å­˜æ–‡å­—åˆ°æª”æ¡ˆ
    python paddle_ocr_tool.py input.pdf --text-output result.txt
        """
    )
    
    parser.add_argument(
        "input",
        help="è¼¸å…¥æª”æ¡ˆæˆ–ç›®éŒ„è·¯å¾‘"
    )
    
    # OCR æ¨¡å¼é¸é …
    parser.add_argument(
        "--mode", "-m",
        type=str,
        default="basic",
        choices=["basic", "structure", "vl", "formula", "hybrid"],
        help="OCR æ¨¡å¼: basic, structure, vl, formula, hybrid (ç‰ˆé¢åˆ†æ+ç²¾ç¢ºOCR)"
    )
    
    # æ–‡ä»¶æ ¡æ­£é¸é …
    parser.add_argument(
        "--orientation-classify",
        action="store_true",
        help="å•Ÿç”¨æ–‡ä»¶æ–¹å‘è‡ªå‹•æ ¡æ­£"
    )
    
    parser.add_argument(
        "--unwarping",
        action="store_true",
        help="å•Ÿç”¨æ–‡ä»¶å½æ›²æ ¡æ­£"
    )
    
    parser.add_argument(
        "--textline-orientation",
        action="store_true",
        help="å•Ÿç”¨æ–‡å­—è¡Œæ–¹å‘åµæ¸¬"
    )
    
    # è¼¸å‡ºé¸é …
    parser.add_argument(
        "--searchable", "-s",
        action="store_true",
        default=True,
        help="ç”Ÿæˆå¯æœå°‹ PDFï¼ˆåƒ… basic æ¨¡å¼ï¼Œé è¨­ï¼šå•Ÿç”¨ï¼‰"
    )
    
    parser.add_argument(
        "--no-searchable",
        action="store_true",
        help="åœç”¨å¯æœå°‹ PDF ç”Ÿæˆ"
    )
    
    parser.add_argument(
        "--output", "-o",
        type=str,
        default=None,
        help="è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆé è¨­ï¼š[åŸå§‹æª”å]_searchable.pdfï¼‰"
    )
    
    parser.add_argument(
        "--text-output", "-t",
        type=str,
        nargs='?',
        const='AUTO',
        default='AUTO',
        help="å°‡è­˜åˆ¥çš„æ–‡å­—å„²å­˜åˆ°æª”æ¡ˆï¼ˆbasic æ¨¡å¼ï¼Œé è¨­ï¼š[åŸå§‹æª”å]_ocr.txtï¼‰"
    )
    
    parser.add_argument(
        "--no-text-output",
        action="store_true",
        help="åœç”¨æ–‡å­—è¼¸å‡º"
    )
    
    parser.add_argument(
        "--markdown-output",
        type=str,
        nargs='?',
        const='AUTO',
        default='AUTO',
        help="è¼¸å‡º Markdown æ ¼å¼ï¼ˆstructure/vl æ¨¡å¼ï¼Œé è¨­ï¼š[åŸå§‹æª”å]_ocr.mdï¼‰"
    )
    
    parser.add_argument(
        "--no-markdown-output",
        action="store_true",
        help="åœç”¨ Markdown è¼¸å‡º"
    )
    
    parser.add_argument(
        "--json-output",
        type=str,
        nargs='?',
        const='AUTO',
        default='AUTO',
        help="è¼¸å‡º JSON æ ¼å¼ï¼ˆstructure/vl æ¨¡å¼ï¼Œé è¨­ï¼š[åŸå§‹æª”å]_ocr.jsonï¼‰"
    )
    
    parser.add_argument(
        "--no-json-output",
        action="store_true",
        help="åœç”¨ JSON è¼¸å‡º"
    )
    
    # Excel è¼¸å‡ºï¼ˆè¡¨æ ¼è­˜åˆ¥ï¼‰
    parser.add_argument(
        "--excel-output",
        type=str,
        nargs='?',
        const='AUTO',
        default=None,
        help="è¼¸å‡º Excel æ ¼å¼ï¼ˆstructure æ¨¡å¼ï¼Œåƒ…è¡¨æ ¼ï¼š[åŸå§‹æª”å]_tables.xlsxï¼‰"
    )
    
    # LaTeX è¼¸å‡ºï¼ˆå…¬å¼è­˜åˆ¥ï¼‰
    parser.add_argument(
        "--latex-output",
        type=str,
        nargs='?',
        const='AUTO',
        default=None,
        help="è¼¸å‡º LaTeX æ ¼å¼ï¼ˆformula æ¨¡å¼ï¼Œé è¨­ï¼š[åŸå§‹æª”å]_formula.texï¼‰"
    )
    
    # é€²åº¦æ¢æ§åˆ¶
    parser.add_argument(
        "--no-progress",
        action="store_true",
        help="åœç”¨é€²åº¦æ¢é¡¯ç¤º"
    )
    
    # å…¶ä»–é¸é …
    parser.add_argument(
        "--dpi",
        type=int,
        default=150,
        help="PDF è½‰åœ–ç‰‡çš„è§£æåº¦ï¼ˆé è¨­ï¼š150ï¼Œé™ä½ä»¥æ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨ï¼‰"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        default="cpu",
        choices=["gpu", "cpu"],
        help="é‹ç®—è¨­å‚™ï¼ˆé è¨­ï¼šcpuï¼Œå¦‚æœ‰ CUDA å¯ç”¨ --device gpuï¼‰"
    )
    
    parser.add_argument(
        "--recursive", "-r",
        action="store_true",
        help="éè¿´è™•ç†å­ç›®éŒ„ï¼ˆåƒ…é©ç”¨æ–¼ç›®éŒ„è¼¸å…¥ï¼‰"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="é¡¯ç¤ºè©³ç´°æ—¥èªŒ"
    )
    
    # ========== ç¿»è­¯é¸é … ==========
    translate_group = parser.add_argument_group('ç¿»è­¯é¸é …', 'ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å‹ç¿»è­¯ PDF å…§å®¹')
    
    translate_group.add_argument(
        "--translate",
        action="store_true",
        help="å•Ÿç”¨ç¿»è­¯åŠŸèƒ½ï¼ˆéœ€è¦ Ollama æœå‹™å’Œ hybrid æ¨¡å¼ï¼‰"
    )
    
    translate_group.add_argument(
        "--source-lang",
        type=str,
        default="auto",
        help="ä¾†æºèªè¨€ï¼ˆauto=è‡ªå‹•åµæ¸¬ï¼Œzh=ä¸­æ–‡ï¼Œzh-cn=ç°¡é«”ä¸­æ–‡ï¼Œzh-tw=ç¹é«”ä¸­æ–‡ï¼Œen=è‹±æ–‡ï¼Œé è¨­ï¼šautoï¼‰"
    )
    
    translate_group.add_argument(
        "--target-lang",
        type=str,
        default="en",
        help="ç›®æ¨™èªè¨€ï¼ˆzh=ä¸­æ–‡ï¼Œzh-cn=ç°¡é«”ä¸­æ–‡ï¼Œzh-tw=ç¹é«”ä¸­æ–‡ï¼Œen=è‹±æ–‡ï¼Œja=æ—¥æ–‡ï¼Œé è¨­ï¼šenï¼‰"
    )
    
    translate_group.add_argument(
        "--ollama-model",
        type=str,
        default="qwen2.5:7b",
        help="Ollama æ¨¡å‹åç¨±ï¼ˆé è¨­ï¼šqwen2.5:7bï¼‰"
    )
    
    translate_group.add_argument(
        "--ollama-url",
        type=str,
        default="http://localhost:11434",
        help="Ollama API åœ°å€ï¼ˆé è¨­ï¼šhttp://localhost:11434ï¼‰"
    )
    
    translate_group.add_argument(
        "--no-mono",
        action="store_true",
        help="ä¸è¼¸å‡ºç´”ç¿»è­¯ PDFï¼ˆåƒ…è¼¸å‡ºé›™èªå°ç…§ï¼‰"
    )
    
    translate_group.add_argument(
        "--no-dual",
        action="store_true",
        help="ä¸è¼¸å‡ºé›™èªå°ç…§ PDFï¼ˆåƒ…è¼¸å‡ºç´”ç¿»è­¯ï¼‰"
    )
    
    translate_group.add_argument(
        "--dual-mode",
        type=str,
        choices=["alternating", "side-by-side"],
        default="alternating",
        help="é›™èªå°ç…§æ¨¡å¼ï¼šalternating(äº¤æ›¿é ) æˆ– side-by-side(ä¸¦æ’)ï¼ˆé è¨­ï¼šalternatingï¼‰"
    )
    
    translate_group.add_argument(
        "--dual-translate-first",
        action="store_true",
        help="é›™èªæ¨¡å¼ä¸­è­¯æ–‡åœ¨å‰ï¼ˆé è¨­ï¼šåŸæ–‡åœ¨å‰ï¼‰"
    )
    
    translate_group.add_argument(
        "--font-path",
        type=str,
        default=None,
        help="è‡ªè¨‚å­—é«”è·¯å¾‘ï¼ˆç”¨æ–¼ç¹ªè£½ç¿»è­¯æ–‡å­—ï¼‰"
    )
    
    args = parser.parse_args()
    
    # é©—è­‰è¼¸å…¥
    input_path = Path(args.input)
    if not input_path.exists():
        logging.error(f"è¼¸å…¥è·¯å¾‘ä¸å­˜åœ¨: {args.input}")
        print(f"éŒ¯èª¤ï¼šè¼¸å…¥è·¯å¾‘ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    # å–å¾—è…³æœ¬æ‰€åœ¨ç›®éŒ„å’Œè¼¸å…¥æª”æ¡ˆçš„åŸºæœ¬åç¨±
    script_dir = Path(__file__).parent.resolve()
    if input_path.is_dir():
        base_name = input_path.name
    else:
        base_name = input_path.stem
    
    logging.info(f"=" * 60)
    logging.info(f"é–‹å§‹åŸ·è¡Œ PaddleOCR å·¥å…·")
    logging.info(f"è¼¸å…¥è·¯å¾‘: {input_path}")
    logging.info(f"OCR æ¨¡å¼: {args.mode}")
    
    # è™•ç† --no-* é¸é …ä¾†è¦†è“‹é è¨­å€¼
    if args.no_searchable:
        args.searchable = False
    if args.no_text_output:
        args.text_output = None
    if args.no_markdown_output:
        args.markdown_output = None
    if args.no_json_output:
        args.json_output = None
    
    # æ ¹æ“šæ¨¡å¼è¨­å®šé è¨­è¼¸å‡ºè·¯å¾‘
    if args.mode == "basic":
        # basic æ¨¡å¼ï¼šè™•ç† text_output å’Œ searchable
        if args.text_output == 'AUTO':
            args.text_output = str(script_dir / f"{base_name}_ocr.txt")
        # å¿½ç•¥å…¶ä»–æ¨¡å¼å°ˆç”¨çš„è¼¸å‡º
        args.markdown_output = None
        args.json_output = None
        args.excel_output = None
        args.latex_output = None
    elif args.mode == "formula":
        # formula æ¨¡å¼ï¼šè™•ç† latex_output
        if args.latex_output == 'AUTO':
            args.latex_output = str(script_dir / f"{base_name}_formula.tex")
        # å¿½ç•¥å…¶ä»–æ¨¡å¼å°ˆç”¨çš„è¼¸å‡º
        args.searchable = False
        args.text_output = None
        args.markdown_output = None
        args.json_output = None
        args.excel_output = None
    elif args.mode == "hybrid":
        # hybrid æ¨¡å¼ï¼šè™•ç† searchable å’Œ markdown_output
        if args.markdown_output == 'AUTO':
            args.markdown_output = str(script_dir / f"{base_name}_hybrid.md")
        # hybrid æ¨¡å¼æœƒè‡ªå‹•ç”Ÿæˆå¯æœå°‹ PDF
        args.searchable = True
        args.text_output = None
        args.json_output = None
        args.excel_output = None
        args.latex_output = None
    else:
        # structure/vl æ¨¡å¼ï¼šè™•ç† markdown_outputã€json_output å’Œ excel_output
        if args.markdown_output == 'AUTO':
            args.markdown_output = str(script_dir / f"{base_name}_ocr.md")
        if args.json_output == 'AUTO':
            args.json_output = str(script_dir / f"{base_name}_ocr.json")
        if args.excel_output == 'AUTO':
            args.excel_output = str(script_dir / f"{base_name}_tables.xlsx")
        # å¿½ç•¥ basic å°ˆç”¨çš„è¼¸å‡º
        args.searchable = False
        args.text_output = None
        args.latex_output = None
    
    # é¡¯ç¤ºè¼¸å‡ºè¨­å®šæ‘˜è¦
    print(f"\nğŸ“‚ è¼¸å…¥ï¼š{input_path}")
    print(f"ğŸ”§ æ¨¡å¼ï¼š{args.mode}")
    if args.mode == "basic":
        print(f"ğŸ“„ å¯æœå°‹ PDFï¼š{'å•Ÿç”¨' if args.searchable else 'åœç”¨'}")
        print(f"ğŸ“ æ–‡å­—è¼¸å‡ºï¼š{args.text_output if args.text_output else 'åœç”¨'}")
    elif args.mode == "formula":
        print(f"ğŸ“ LaTeX è¼¸å‡ºï¼š{args.latex_output if args.latex_output else 'åœç”¨'}")
    elif args.mode == "hybrid":
        print(f"ğŸ“„ å¯æœå°‹ PDFï¼šå•Ÿç”¨ï¼ˆæ··åˆæ¨¡å¼ï¼‰")
        print(f"ğŸ“ Markdown è¼¸å‡ºï¼š{args.markdown_output if args.markdown_output else 'åœç”¨'}")
    else:
        print(f"ğŸ“ Markdown è¼¸å‡ºï¼š{args.markdown_output if args.markdown_output else 'åœç”¨'}")
        print(f"ğŸ“Š JSON è¼¸å‡ºï¼š{args.json_output if args.json_output else 'åœç”¨'}")
        print(f"ğŸ“ˆ Excel è¼¸å‡ºï¼š{args.excel_output if args.excel_output else 'åœç”¨'}")
    if not args.no_progress and HAS_TQDM:
        print(f"ğŸ“Š é€²åº¦æ¢ï¼šå•Ÿç”¨")
    print()
    
    # æª¢æŸ¥é€²éšæ¨¡çµ„å¯ç”¨æ€§
    if args.mode == "structure" and not HAS_STRUCTURE:
        print("éŒ¯èª¤ï¼šPP-StructureV3 æ¨¡çµ„ä¸å¯ç”¨")
        print("è«‹ç¢ºèªå·²å®‰è£æœ€æ–°ç‰ˆ paddleocr: pip install -U paddleocr")
        sys.exit(1)
    
    if args.mode == "vl" and not HAS_VL:
        print("éŒ¯èª¤ï¼šPaddleOCR-VL æ¨¡çµ„ä¸å¯ç”¨")
        print("è«‹ç¢ºèªå·²å®‰è£æœ€æ–°ç‰ˆ paddleocr: pip install -U paddleocr")
        sys.exit(1)
    
    if args.mode == "formula" and not HAS_FORMULA:
        print("éŒ¯èª¤ï¼šFormulaRecPipeline æ¨¡çµ„ä¸å¯ç”¨")
        print("è«‹ç¢ºèªå·²å®‰è£æœ€æ–°ç‰ˆ paddleocr: pip install -U paddleocr")
        sys.exit(1)
    
    if args.mode == "hybrid" and not HAS_STRUCTURE:
        print("éŒ¯èª¤ï¼šHybrid æ¨¡å¼éœ€è¦ PP-StructureV3 æ¨¡çµ„")
        print("è«‹ç¢ºèªå·²å®‰è£æœ€æ–°ç‰ˆ paddleocr: pip install -U paddleocr")
        sys.exit(1)
    
    # åˆå§‹åŒ– OCR å·¥å…·
    tool = PaddleOCRTool(
        mode=args.mode,
        use_orientation_classify=args.orientation_classify,
        use_doc_unwarping=args.unwarping,
        use_textline_orientation=args.textline_orientation,
        device=args.device
    )
    
    # æ ¹æ“šæ¨¡å¼è™•ç†
    if args.mode == "formula":
        # å…¬å¼è­˜åˆ¥æ¨¡å¼
        result = tool.process_formula(
            input_path=str(input_path),
            latex_output=args.latex_output
        )
        
        if result.get("error"):
            print(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {result['error']}")
        else:
            print(f"\nâœ“ å…¬å¼è­˜åˆ¥å®Œæˆï¼å…±è­˜åˆ¥ {len(result['formulas'])} å€‹å…¬å¼")
            if result.get("latex_file"):
                print(f"  LaTeX æª”æ¡ˆ: {result['latex_file']}")
    
    elif args.mode in ["structure", "vl"]:
        # çµæ§‹åŒ–è™•ç†æ¨¡å¼
        result = tool.process_structured(
            input_path=str(input_path),
            markdown_output=args.markdown_output,
            json_output=args.json_output,
            excel_output=args.excel_output
        )
        
        if result.get("error"):
            print(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {result['error']}")
        else:
            print(f"\nâœ“ è™•ç†å®Œæˆï¼å…±è™•ç† {result['pages_processed']} é ")
            if result.get("markdown_files"):
                print(f"  Markdown æª”æ¡ˆ: {', '.join(result['markdown_files'])}")
            if result.get("json_files"):
                print(f"  JSON æª”æ¡ˆ: {', '.join(result['json_files'])}")
            if result.get("excel_files"):
                print(f"  Excel æª”æ¡ˆ: {', '.join(result['excel_files'])}")
    
    elif args.mode == "hybrid":
        # æ··åˆæ¨¡å¼ï¼šç‰ˆé¢åˆ†æ + ç²¾ç¢º OCR
        show_progress = not args.no_progress
        
        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨ç¿»è­¯åŠŸèƒ½
        if hasattr(args, 'translate') and args.translate:
            # ç¿»è­¯æ¨¡å¼
            if not HAS_TRANSLATOR:
                print("éŒ¯èª¤ï¼šç¿»è­¯æ¨¡çµ„ä¸å¯ç”¨")
                print("è«‹ç¢ºèª pdf_translator.py å­˜åœ¨ä¸”ä¾è³´å·²å®‰è£")
                sys.exit(1)
            
            print(f"ğŸŒ ç¿»è­¯åŠŸèƒ½ï¼šå•Ÿç”¨")
            print(f"   ä¾†æºèªè¨€ï¼š{args.source_lang}")
            print(f"   ç›®æ¨™èªè¨€ï¼š{args.target_lang}")
            print(f"   Ollama æ¨¡å‹ï¼š{args.ollama_model}")
            print(f"   ç´”ç¿»è­¯ PDFï¼š{'åœç”¨' if args.no_mono else 'å•Ÿç”¨'}")
            print(f"   é›™èªå°ç…§ PDFï¼š{'åœç”¨' if args.no_dual else f'å•Ÿç”¨ ({args.dual_mode})'}")
            
            result = tool.process_translate(
                input_path=str(input_path),
                output_path=args.output,
                source_lang=args.source_lang,
                target_lang=args.target_lang,
                ollama_model=args.ollama_model,
                ollama_url=args.ollama_url,
                no_mono=args.no_mono,
                no_dual=args.no_dual,
                dual_mode=args.dual_mode,
                dual_translate_first=args.dual_translate_first,
                font_path=args.font_path,
                dpi=args.dpi,
                show_progress=show_progress
            )
            
            if result.get("error"):
                print(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {result['error']}")
            else:
                print(f"\nâœ“ ç¿»è­¯è™•ç†å®Œæˆï¼å…±è™•ç† {result['pages_processed']} é ")
                if result.get("searchable_pdf"):
                    print(f"  ğŸ” å¯æœå°‹ PDF: {result['searchable_pdf']}")
                if result.get("markdown_file"):
                    print(f"  ğŸ“ Markdown æª”æ¡ˆ: {result['markdown_file']}")
                if result.get("translated_pdf"):
                    print(f"  ğŸŒ ç¿»è­¯å¾Œ PDF: {result['translated_pdf']}")
                if result.get("bilingual_pdf"):
                    print(f"  ğŸ“– é›™èªå°ç…§ PDF: {result['bilingual_pdf']}")
        else:
            # ä¸€èˆ¬ hybrid æ¨¡å¼ï¼ˆç„¡ç¿»è­¯ï¼‰
            result = tool.process_hybrid(
                input_path=str(input_path),
                output_path=args.output,
                markdown_output=args.markdown_output,
                dpi=args.dpi,
                show_progress=show_progress
            )
            
            if result.get("error"):
                print(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {result['error']}")
            else:
                print(f"\nâœ“ æ··åˆæ¨¡å¼è™•ç†å®Œæˆï¼å…±è™•ç† {result['pages_processed']} é ")
                if result.get("searchable_pdf"):
                    print(f"  å¯æœå°‹ PDF: {result['searchable_pdf']}")
                if result.get("markdown_file"):
                    print(f"  Markdown æª”æ¡ˆ: {result['markdown_file']}")
    
    else:
        # basic æ¨¡å¼ï¼ˆåŸæœ‰é‚è¼¯ï¼‰
        all_text = []
        show_progress = not args.no_progress
        
        # è™•ç†è¼¸å…¥
        if input_path.is_dir():
            # ç›®éŒ„è™•ç†
            results = tool.process_directory(
                str(input_path),
                output_path=args.output,
                searchable=args.searchable,
                recursive=args.recursive
            )
            
            for file_path, file_results in results.items():
                text = tool.get_text(file_results)
                if text:
                    all_text.append(f"=== {file_path} ===\n{text}")
        
        elif input_path.suffix.lower() == SUPPORTED_PDF_FORMAT:
            # PDF è™•ç†ï¼ˆä½¿ç”¨é€²åº¦æ¢ï¼‰
            results, output_path = tool.process_pdf(
                str(input_path),
                output_path=args.output,
                searchable=args.searchable,
                dpi=args.dpi,
                show_progress=show_progress
            )
            
            for page_num, page_results in enumerate(results, 1):
                text = tool.get_text(page_results)
                if text:
                    all_text.append(f"=== ç¬¬ {page_num} é  ===\n{text}")
        
        elif input_path.suffix.lower() in SUPPORTED_IMAGE_FORMATS:
            # åœ–ç‰‡è™•ç†
            results = tool.process_image(str(input_path))
            
            if args.searchable:
                output_path = args.output or str(input_path.with_suffix('.pdf'))
                pdf_generator = PDFGenerator(output_path)
                pdf_generator.add_page(str(input_path), results)
                pdf_generator.save()
            
            text = tool.get_text(results)
            if text:
                all_text.append(text)
        
        else:
            print(f"éŒ¯èª¤ï¼šä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {input_path.suffix}")
            sys.exit(1)
        
        # è¼¸å‡ºçµæœ
        combined_text = "\n\n".join(all_text)
        
        if args.text_output:
            # å¦‚æœè¼¸å‡ºè·¯å¾‘ä¸æ˜¯çµ•å°è·¯å¾‘ï¼Œå‰‡ç›¸å°æ–¼è…³æœ¬ç›®éŒ„
            text_output_path = Path(args.text_output)
            if not text_output_path.is_absolute():
                text_output_path = script_dir / text_output_path
            
            # å„²å­˜åˆ°æª”æ¡ˆ
            with open(text_output_path, 'w', encoding='utf-8') as f:
                f.write(combined_text)
            print(f"âœ“ æ–‡å­—å·²å„²å­˜ï¼š{text_output_path}")
        
        # å¦‚æœå…©å€‹è¼¸å‡ºéƒ½åœç”¨ï¼Œå‰‡è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿ
        if not args.text_output and not args.searchable and combined_text:
            print("\n" + "=" * 50)
            print("OCR è¾¨è­˜çµæœï¼š")
            print("=" * 50)
            print(combined_text)
        
        print("\nâœ“ è™•ç†å®Œæˆï¼")


if __name__ == "__main__":
    log_file = None
    try:
        # å…ˆè¨­å®šæ—¥èªŒï¼ˆåœ¨ä»»ä½•å…¶ä»–æ“ä½œä¹‹å‰ï¼‰
        log_file = setup_logging()
        
        # åŸ·è¡Œä¸»ç¨‹å¼
        main()
        
    except KeyboardInterrupt:
        if log_file:
            logging.info("\nä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ (Ctrl+C)")
        print("\n\nå·²ä¸­æ–·åŸ·è¡Œ")
        sys.exit(0)
        
    except Exception as e:
        error_msg = f"ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {str(e)}"
        if log_file:
            logging.error("=" * 60)
            logging.error(error_msg)
            logging.error(traceback.format_exc())
            logging.error("=" * 60)
            # å¼·åˆ¶ flush
            for handler in logging.root.handlers:
                handler.flush()
        
        print(f"\n{'='*60}")
        print(f"éŒ¯èª¤ï¼š{error_msg}")
        print(f"è©³ç´°éŒ¯èª¤è¨Šæ¯å·²è¨˜éŒ„åˆ°ï¼š{log_file}")
        print(f"{'='*60}\n")
        traceback.print_exc()
        sys.exit(1)
    
    finally:
        # ç¢ºä¿æ—¥èªŒè¢« flush
        if log_file:
            logging.info("ç¨‹å¼çµæŸ")
            for handler in logging.root.handlers:
                handler.flush()
                handler.close()


